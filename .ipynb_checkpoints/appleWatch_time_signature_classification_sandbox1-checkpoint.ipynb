{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\textbf{Inferring Musical Time Signature via Apple Watch Logs of Conductor Wrist Motion}$\n",
    "\n",
    "$\\textbf{Author:}\\text{ Ryan Burns}$\n",
    "\n",
    "$\\text{This notebook is dedicated to analysis of componentwise spectrograms as input feature to deep learning classification models.}$\n",
    "\n",
    "$\\textbf{Motion Class Labels:}$\n",
    "\n",
    "$\\text{All class labels are defined for a right-handed user. An orchestral conductor varies their baton pattern according to 1 of 4 possible states, }$\n",
    "$\\text{comprised of 3 time signature classes and a resting class (i.e., cessation of baton motion).}$\n",
    "\n",
    "$\\text{0 }\\leftrightarrow [1\\enspace0\\enspace0\\enspace0]\\leftrightarrow \\text{REST}\\Longrightarrow\\text{conductor has ceased baton motion (no conducting)}$\n",
    "\n",
    "$\\text{1 }\\leftrightarrow [0\\enspace1\\enspace0\\enspace0]\\leftrightarrow {2/4}\\Longrightarrow\\text{conductor proceeds with baton motion consistent with a }\\mathbf{\\genfrac{}{}{0pt}{}{2}{4}}\\text{ time signature}$\n",
    "\n",
    "$\\text{2 }\\leftrightarrow [0\\enspace0\\enspace1\\enspace0]\\leftrightarrow {3/4}\\Longrightarrow\\text{conductor proceeds with baton motion consistent with a }\\mathbf{\\genfrac{}{}{0pt}{}{3}{4}}\\text{ time signature}$\n",
    "\n",
    "$\\text{3 }\\leftrightarrow [0\\enspace0\\enspace0\\enspace1]\\leftrightarrow {4/4}\\Longrightarrow\\text{conductor proceeds with baton motion consistent with a }\\mathbf{\\genfrac{}{}{0pt}{}{4}{4}}\\text{ time signature}$\n",
    "\n",
    "$\\text{For more information on musical time signatures, visit: }\\textit{https://en.wikipedia.org/wiki/Time_signature}.$\n",
    "\n",
    "![title](baton_motion.png)\n",
    "\n",
    "$\\text{The baton patterns for each time signature of interest are depicted diagramatically above. We assume a tech enthusiast conductor who desires}$\n",
    "$\\text{an Apple Watch app/experience for automatic discrimination between the 3 time signatures above, in addition to a catch-all }\\textit{at-rest}\\text{ state. We }$\n",
    "$\\text{also assume that this conductor would like automatic time-signature inference to be as tempo-agnostic as possible. Be it }\\textit{largo}\\text{ or }\\textit{prestissimo}\\text{,}$\n",
    "$\\text{we assume that the tempo of the musical composition of question would not fool the ideal baton pattern classifier. As such, while the amount}$\n",
    "$\\text{of data collected for this analysis is still limited in its size and diversity (i.e., we can assume overfit models), efforts have been made during}$\n",
    "$\\text{data collection to vary the tempo across each time signature's constituent wrist motion observations. The duration (in seconds or measures)}$\n",
    "$\\text{of each time signature's wrist motion subsequence is also varied during collection. We create an aggregated dataset of independent concatenated}$\n",
    "$\\text{collects for supervised learning in the code below.}$\n",
    "\n",
    "$\\textbf{Note On Labeling:}$\n",
    "\n",
    "$\\text{SensorLog labels are recorded in real time using the app's class label buttons for a streaming iPhone. This iPhone logs data concurrently with}$\n",
    "$\\text{an Apple Watch, which also reports its own class labels. Since toggling of the Apple Watch's class labels using the SensorLog UI on the watch }$\n",
    "$\\text{face would interfere with data collection of wrist motion, we use the }\\textit{iPhone}\\text{ to log wrist motion labels. By time-aligning the iPhone and Apple}$\n",
    "$\\text{Watch streams below (i.e., using POSIX timestamps), we can readily provide wrist motion labels for the Apple Watch motion signals without}$\n",
    "$\\text{interfering with their trajectory as just described. In short, real-time motion labeling is available through dual stream of Apple Watch }$\n",
    "$\\text{iPhone data, where the former provides the motion observations of interest and the latter provides a mechanism for real-time motion labeling.}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\textbf{Import Packages}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import getcwd, environ;\n",
    "from itertools import product as iter_prod;\n",
    "from matplotlib import pyplot as plt;\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from numpy import array, hstack, argmax, ones, zeros, log10;\n",
    "from numpy import logical_or, logical_not, expand_dims, flip;\n",
    "from numpy import  abs, arange, shape, newaxis, sum, flipud;\n",
    "from numpy import nan_to_num, transpose;\n",
    "from scipy.signal import spectrogram;\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model;\n",
    "from tensorflow.keras.optimizers import RMSprop;\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy;\n",
    "from tensorflow.keras.metrics import Precision, Recall, AUC;\n",
    "from tensorflow.keras.layers import Dropout, LSTM, Dense, Conv2D;\n",
    "from tensorflow.keras.layers import Conv2D, Reshape, Conv1D;\n",
    "from tensorflow.keras.layers import AveragePooling2D, AveragePooling1D;\n",
    "from tensorflow.keras.layers import Input, GaussianNoise, ConvLSTM2D;\n",
    "from sklearn.metrics import confusion_matrix;\n",
    "\n",
    "from SensorLogUtils import convert_iPhone_units;\n",
    "\n",
    "environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\textbf{Class Label Definitions}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REST</th>\n",
       "      <th>2/4</th>\n",
       "      <th>3/4</th>\n",
       "      <th>4/4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>REST</td>\n",
       "      <td>2/4</td>\n",
       "      <td>3/4</td>\n",
       "      <td>4/4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <td>no conducting / baton pattern</td>\n",
       "      <td>conducting pattern for a 2/4 time signature</td>\n",
       "      <td>conducting pattern for a 3/4 time signature</td>\n",
       "      <td>conducting pattern for a 4/4 time signature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-hot label</th>\n",
       "      <td>[1, 0, 0, 0]</td>\n",
       "      <td>[0, 1, 0, 0]</td>\n",
       "      <td>[0, 0, 1, 0]</td>\n",
       "      <td>[0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ordinal label</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        REST  \\\n",
       "id                                      REST   \n",
       "description    no conducting / baton pattern   \n",
       "1-hot label                     [1, 0, 0, 0]   \n",
       "ordinal label                              0   \n",
       "\n",
       "                                                       2/4  \\\n",
       "id                                                     2/4   \n",
       "description    conducting pattern for a 2/4 time signature   \n",
       "1-hot label                                   [0, 1, 0, 0]   \n",
       "ordinal label                                            1   \n",
       "\n",
       "                                                       3/4  \\\n",
       "id                                                     3/4   \n",
       "description    conducting pattern for a 3/4 time signature   \n",
       "1-hot label                                   [0, 0, 1, 0]   \n",
       "ordinal label                                            2   \n",
       "\n",
       "                                                       4/4  \n",
       "id                                                     4/4  \n",
       "description    conducting pattern for a 4/4 time signature  \n",
       "1-hot label                                   [0, 0, 0, 1]  \n",
       "ordinal label                                            3  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ordinal motion class labels\n",
    "class_table = pd.DataFrame({\n",
    "    'REST': {\n",
    "        'id': 'REST', \n",
    "        'description': 'no conducting / baton pattern',\n",
    "        '1-hot label': [1,0,0,0],\n",
    "        'ordinal label': 0\n",
    "    },\n",
    "    '2/4': {\n",
    "        'id': '2/4', \n",
    "        'description': 'conducting pattern for a 2/4 time signature',\n",
    "        '1-hot label': [0,1,0,0],\n",
    "        'ordinal label': 1\n",
    "    },\n",
    "    '3/4': {\n",
    "        'id': '3/4', \n",
    "        'description':'conducting pattern for a 3/4 time signature',\n",
    "        '1-hot label': [0,0,1,0],\n",
    "        'ordinal label': 2\n",
    "    },\n",
    "    '4/4': {\n",
    "        'id': '4/4', \n",
    "        'description':'conducting pattern for a 4/4 time signature',\n",
    "        '1-hot label': [0,0,0,1],\n",
    "        'ordinal label': 3\n",
    "    }\n",
    "});\n",
    "\n",
    "# Number of classes\n",
    "C = 4;\n",
    "\n",
    "# Print class table\n",
    "class_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\textbf{Specify & Load Dataset}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "# Specify data #\n",
    "################\n",
    "\n",
    "# Specify local data storage path\n",
    "data_path = getcwd() + '/data';\n",
    "\n",
    "# Collect file string ID\n",
    "collect_IDs = [\n",
    "    'time_signatures_collect1',\n",
    "    'time_signatures_collect2'\n",
    "];\n",
    "\n",
    "# Build string filename corresponding to collect_ID\n",
    "collect_files = [\n",
    "    (data_path + '/labeled_' + collect_ID + '_appleWatch.csv')\n",
    "for collect_ID in collect_IDs];\n",
    "\n",
    "#############\n",
    "# Load data #\n",
    "#############\n",
    "\n",
    "# Load and concatenate dataframes for all\n",
    "# labeled collects in list collect_IDs\n",
    "df = pd.concat([pd.read_csv(f, \n",
    "    error_bad_lines=False,\n",
    "    warn_bad_lines=False)\n",
    "    for f in collect_files\n",
    "],axis=0,ignore_index=True);\n",
    "\n",
    "# Data fields (column headers)\n",
    "fields = [fd for fd in df];\n",
    "\n",
    "# Length of dataframe\n",
    "N = len(df); # (samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\textbf{Select IMU Data & 1-Hot Class Labels}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select input signals\n",
    "x = nan_to_num(array(df[[\n",
    "    'accelerometerAccelerationX(m/s^2)',\n",
    "    'accelerometerAccelerationY(m/s^2)',\n",
    "    'accelerometerAccelerationZ(m/s^2)',\n",
    "    'motionRotationRateX(rad/s)',\n",
    "    'motionRotationRateY(rad/s)',\n",
    "    'motionRotationRateZ(rad/s)'\n",
    "]]));\n",
    "\n",
    "# Define 1-hot labels\n",
    "y = nan_to_num(array(df[[\n",
    "    \n",
    "    # List all class headers in table above\n",
    "    class_name for class_name in class_table\n",
    "]]));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\textbf{Specify Sliding Observation Window Parameters}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of raw sensor samples (N)\n",
    "# and their dimensionality (D)\n",
    "N, D = shape(x);\n",
    "\n",
    "# Sliding obs. window length\n",
    "M = 1024; # (samples)\n",
    "\n",
    "# Step size of obs. window\n",
    "m = 4;  # (samples)\n",
    "\n",
    "# Linear grid for sliding observation\n",
    "# window reflecting window length & step\n",
    "# size specified above, mapped to raw\n",
    "# sensor samples n = M, M + m, M + 2m, ...\n",
    "obs_idx = [n for n in range(M,N,m)];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\textbf{Define Observations & Class Labels}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Windowed 6D spectrogram observation sequence input to model\n",
    "X = (array([[spectrogram(x[(n - M):n,d],\n",
    "    window='blackmanharris',fs=100,\n",
    "    nperseg=int(M/4),nfft=M)[2] \n",
    "    for d in range(D)] for n in obs_idx\n",
    "]));\n",
    "\n",
    "# Overwrite N,M,D with new dimensionality\n",
    "N,K,M,D = shape(X);\n",
    "\n",
    "# Ground truth 1-hot window-resolution class labels\n",
    "Y = array([\n",
    "    [1 if c == argmax(sum(y[(n - M):n,:],0)) \n",
    "    else 0 for c in range(C)] for n in obs_idx]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\textbf{Training Parameters}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fraction of dataset to hold \n",
    "# out for model validation\n",
    "pct_validation = 0.2;\n",
    "\n",
    "# Total number of obs.\n",
    "N_obs = len(X);\n",
    "\n",
    "# Number of training epochs\n",
    "N_epoch = 200;\n",
    "\n",
    "# Number of batches\n",
    "N_batch = int(N_obs / 3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\textbf{Define Machine Learning Model}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         [(None, 6, 513, 4)]       0         \n",
      "_________________________________________________________________\n",
      "gaussian_noise_8 (GaussianNo (None, 6, 513, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 1, 1, 256)         3152128   \n",
      "_________________________________________________________________\n",
      "average_pooling2d_8 (Average (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1, 1, 64)          16448     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "reshape_6 (Reshape)          (None, 64, 1)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 64, 64)            128       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_5 (Average (None, 8, 64)             0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 16)                5184      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 3,173,956\n",
      "Trainable params: 3,173,956\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#####################################################\n",
    "# Define model architecture w/ Keras functional API #\n",
    "#####################################################\n",
    "\n",
    "# Input layer - M x D observation window\n",
    "input_layer = Input((K,M,D));\n",
    "\n",
    "# Add Gaussian noise to M x D input\n",
    "h0 = GaussianNoise(1e-4)(input_layer);\n",
    "\n",
    "# Convolutional layer\n",
    "h1 = Conv2D(filters=256,\n",
    "    kernel_size=(K,M),\n",
    "    activation='relu')(h0);\n",
    "\n",
    "# # Averge pooling layer\n",
    "h2 = AveragePooling2D(pool_size=(1,1))(h1);\n",
    "\n",
    "# Dense hyperbolic tangent activation layer\n",
    "h3 = Dense(64,activation='tanh')(h2);\n",
    "\n",
    "# Dropout (25%)\n",
    "h4 = Dropout(0.25)(h3);\n",
    "\n",
    "# Reshape layer\n",
    "h5 = Reshape((64,1))(h4);\n",
    "\n",
    "# 1D convolutional layer\n",
    "h6 = Conv1D(64,1,activation='tanh')(h5);\n",
    "\n",
    "# Averge pooling layer\n",
    "h7 = AveragePooling1D(pool_size=(8))(h6);\n",
    "\n",
    "# Long short-term memory layer\n",
    "h8 = LSTM(C*C,activation='tanh',\n",
    "    dropout=0.5,\n",
    "    recurrent_dropout=0.5)(h7);\n",
    "\n",
    "# Output layer - C x 1 softmax class activation \n",
    "output_layer = Dense(C,activation='softmax')(h8);\n",
    "\n",
    "# Set up Keras Model() instance\n",
    "model = Model(\n",
    "    inputs=input_layer,  # Model inputs\n",
    "    outputs=output_layer # Model outputs\n",
    ");\n",
    "\n",
    "###########################\n",
    "# Define loss & optimizer #\n",
    "###########################\n",
    "\n",
    "# Set RMSprop optimization for \n",
    "# speed-of-convergence purposes\n",
    "opt = RMSprop(\n",
    "    learning_rate=0.001,\n",
    "    rho=0.9,\n",
    "    momentum=0.001,\n",
    "    epsilon=1e-07,\n",
    "    name=\"RMSprop\"\n",
    ");\n",
    "\n",
    "# Model compilation, using categorical\n",
    "# cross-entropy error w/ RMSprop\n",
    "model.compile(\n",
    "    \n",
    "    # Error/loss function\n",
    "    loss='categorical_crossentropy', \n",
    "    \n",
    "    # Use RMSprop\n",
    "    optimizer=opt,\n",
    "    \n",
    "    # List metrics here\n",
    "    metrics=[\n",
    "        CategoricalAccuracy(),\n",
    "        AUC(),\n",
    "        Precision(),\n",
    "        Recall()\n",
    "    ]\n",
    ");\n",
    "\n",
    "# Print a summary table\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\textbf{Train Machine Learning Model}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16236 samples, validate on 4060 samples\n",
      "Epoch 1/200\n",
      "16236/16236 [==============================] - 104s 6ms/sample - loss: 1.3819 - categorical_accuracy: 0.3044 - auc: 0.5417 - precision: 0.3333 - recall: 6.1592e-05 - val_loss: 1.3463 - val_categorical_accuracy: 0.3717 - val_auc: 0.6313 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/200\n",
      " 6765/16236 [===========>..................] - ETA: 59s"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-de0dd665acc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# Parallelize job across 2 workers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m );\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Model training\n",
    "model.fit(\n",
    "    \n",
    "    # Input dataset\n",
    "    x=X, # windowed observations\n",
    "    y=Y, # 1-hot motion class labels\n",
    "    \n",
    "    # Batch size\n",
    "    batch_size=N_batch,\n",
    "    \n",
    "    # Number of training epochs\n",
    "    epochs=N_epoch,\n",
    "    \n",
    "    # Print progress\n",
    "    verbose=1,\n",
    "    \n",
    "    # Set aside fraction for validation\n",
    "    validation_split=pct_validation,\n",
    "    \n",
    "    # False for time series\n",
    "    shuffle=False,\n",
    "    \n",
    "    # Other misc params\n",
    "    sample_weight=None,\n",
    "    validation_freq=1,\n",
    "    max_queue_size=10,\n",
    "    \n",
    "    # Parallelize job across 2 workers\n",
    "    workers=2,\n",
    "    use_multiprocessing=True\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\textbf{Metrics vs. Training Epoch}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "# Text legend labels for training set curves\n",
    "train_set_lbl = ('Training Set (' + \n",
    "    str(int(100 * (1 - pct_validation))) + '%)');\n",
    "    \n",
    "# Text legend labels for validation set curves\n",
    "val_set_lbl = ('Training Set (' + \n",
    "    str(int(100 * (1 - pct_validation))) + '%)');\n",
    "\n",
    "# New figure\n",
    "loss_fig = plt.figure(figsize=(9.9,12));\n",
    "\n",
    "#############\n",
    "# Loss plot #\n",
    "#############\n",
    "ax1 = plt.subplot(5,1,1);\n",
    "\n",
    "# Add grid to axes\n",
    "plt.grid(color='k',alpha=0.25);\n",
    "\n",
    "# Linear grid of training epochs\n",
    "epochs = arange(0,N_epoch);\n",
    "\n",
    "# Cross-entropy error (dB) - training set\n",
    "plt.plot(epochs,10 * log10(\n",
    "    model.history.history['loss']),\n",
    "    '.-',c='g',alpha=0.5,\n",
    "    label=train_set_lbl);\n",
    "\n",
    "# Cross-entropy error (dB) - validation set\n",
    "plt.plot(epochs,10 * log10(\n",
    "    model.history.history['val_loss']),\n",
    "    '.-',c='k',alpha=0.5,\n",
    "    label=val_set_lbl);\n",
    "\n",
    "# Set x-axis limits\n",
    "plt.xlim([epochs[0],epochs[-1]]);\n",
    "\n",
    "# Title\n",
    "plt.title(r'Cross-Entropy Error vs. Training Epoch $\\varepsilon$',\n",
    "          fontsize=16,weight='bold');\n",
    "\n",
    "# x-axis label\n",
    "plt.xlabel(r'Epoch $\\varepsilon$',fontsize=14);\n",
    "\n",
    "# y-axis label\n",
    "plt.ylabel(r'Error${}_{\\varepsilon}$ (dB)',fontsize=14);\n",
    "\n",
    "# Legend\n",
    "plt.legend();\n",
    "\n",
    "#################\n",
    "# Accuracy plot #\n",
    "#################\n",
    "plt.subplot(5,1,2,sharex=ax1);\n",
    "\n",
    "# Add grid to axes\n",
    "plt.grid(color='k',alpha=0.25);\n",
    "\n",
    "# Cross-entropy error (dB) - training set\n",
    "plt.plot(epochs,model.history.history['categorical_accuracy'],\n",
    "    '.-',c='g',alpha=0.5,label=train_set_lbl);\n",
    "\n",
    "# Cross-entropy error (dB) - validation set\n",
    "plt.plot(epochs,model.history.history['val_categorical_accuracy'],\n",
    "    '.-',c='k',alpha=0.5,label=val_set_lbl);\n",
    "\n",
    "# Set x-axis limits\n",
    "plt.xlim([epochs[0],epochs[-1]]);\n",
    "\n",
    "# Title\n",
    "plt.title(r'Categorical Accuracy vs. Training Epoch $\\varepsilon$',\n",
    "          fontsize=16,weight='bold');\n",
    "\n",
    "# x-axis label\n",
    "plt.xlabel(r'Epoch $\\varepsilon$',fontsize=14);\n",
    "\n",
    "# y-axis label\n",
    "plt.ylabel(r'Accuracy${}_{\\varepsilon}$ ($\\times100\\%$)',fontsize=14);\n",
    "\n",
    "# Legend\n",
    "plt.legend();\n",
    "\n",
    "##################\n",
    "# Precision plot #\n",
    "##################\n",
    "plt.subplot(5,1,3,sharex=ax1);\n",
    "\n",
    "# Add grid to axes\n",
    "plt.grid(color='k',alpha=0.25);\n",
    "\n",
    "# Cross-entropy error (dB) - training set\n",
    "plt.plot(epochs,model.history.history['precision'],\n",
    "    '.-',c='g',alpha=0.5,label=train_set_lbl);\n",
    "\n",
    "# Cross-entropy error (dB) - validation set\n",
    "plt.plot(epochs,model.history.history['val_precision'],\n",
    "    '.-',c='k',alpha=0.5,label=val_set_lbl);\n",
    "\n",
    "# Set x-axis limits\n",
    "plt.xlim([epochs[0],epochs[-1]]); \n",
    "\n",
    "# x-axis label\n",
    "plt.xlabel(r'Epoch $\\varepsilon$',fontsize=14);\n",
    "\n",
    "# y-axis label\n",
    "plt.ylabel(r'Precision${}_{\\varepsilon}$',fontsize=14);\n",
    "\n",
    "# Legend\n",
    "plt.legend();\n",
    "\n",
    "###############\n",
    "# Recall plot #\n",
    "###############\n",
    "plt.subplot(5,1,4,sharex=ax1);\n",
    "\n",
    "# Add grid to axes\n",
    "plt.grid(color='k',alpha=0.25);\n",
    "\n",
    "# Cross-entropy error (dB) - training set\n",
    "plt.plot(epochs,model.history.history['recall'],\n",
    "    '.-',c='g',alpha=0.5,label=train_set_lbl);\n",
    "\n",
    "# Cross-entropy error (dB) - validation set\n",
    "plt.plot(epochs,model.history.history['val_recall'],\n",
    "    '.-',c='k',alpha=0.5,label=val_set_lbl);\n",
    "\n",
    "# Set x-axis limits\n",
    "plt.xlim([epochs[0],epochs[-1]]);\n",
    "\n",
    "# Title\n",
    "plt.title(r'Recall vs. Training Epoch $\\varepsilon$',\n",
    "          fontsize=16,weight='bold');\n",
    "\n",
    "# x-axis label\n",
    "plt.xlabel(r'Epoch $\\varepsilon$',fontsize=14);\n",
    "\n",
    "# y-axis label\n",
    "plt.ylabel(r'Recall${}_{\\varepsilon}$',fontsize=14);\n",
    "\n",
    "# Legend\n",
    "plt.legend();\n",
    "\n",
    "############\n",
    "# AUC plot #\n",
    "############\n",
    "plt.subplot(5,1,5,sharex=ax1);\n",
    "\n",
    "# Add grid to axes\n",
    "plt.grid(color='k',alpha=0.25);\n",
    "\n",
    "# Cross-entropy error (dB) - training set\n",
    "plt.plot(epochs,model.history.history['auc'],\n",
    "    '.-',c='g',alpha=0.5,label=train_set_lbl);\n",
    "\n",
    "# Cross-entropy error (dB) - validation set\n",
    "plt.plot(epochs,model.history.history['val_auc'],\n",
    "    '.-',c='k',alpha=0.5,label=val_set_lbl);\n",
    "\n",
    "# Set x-axis limits\n",
    "plt.xlim([epochs[0],epochs[-1]]);\n",
    "\n",
    "# Title\n",
    "plt.title(r'Area Under ROC Curve vs. Training Epoch $\\varepsilon$',\n",
    "          fontsize=16,weight='bold');\n",
    "\n",
    "# x-axis label\n",
    "plt.xlabel(r'Epoch $\\varepsilon$',fontsize=14);\n",
    "\n",
    "# y-axis label\n",
    "plt.ylabel(r'AUC${}_{\\varepsilon}$',fontsize=14);\n",
    "\n",
    "# Legend\n",
    "plt.legend();\n",
    "\n",
    "# Optimize layout\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\textbf{Pass Entire Dataset (i.e., Train }\\cup\\textbf{ Validation) to Model}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C x 1 class prediction for entire dataset\n",
    "Y_hat = model.predict(\n",
    "    X,                        # Input data\n",
    "    batch_size=N_batch,       # Batch size\n",
    ");\n",
    "\n",
    "# Cast 1-hot class labels as ordinal labels\n",
    "y_hat = argmax(Y_hat,axis=1); # Predictions\n",
    "y_true = argmax(Y,axis=1);    # Ground truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\textbf{Confusion Matrix Using Predictions Output Above}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "#    Compute Matrix:    #\n",
    "#########################\n",
    "\n",
    "# Use the sklearn confusion matrix function\n",
    "confusion_mat = confusion_matrix(y_true,y_hat,\n",
    "    labels=[c for c in range(C)],sample_weight=None);\n",
    "\n",
    "#########################\n",
    "#   Confusion Plotter:  # - adapated from online example\n",
    "#########################\n",
    "\n",
    "def plot_confusion_matrix(C,classes,normalize=False,\n",
    "            title='Confusion matrix',cmap=plt.cm.Greens):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Let epsilon > 0 be small...\n",
    "    epsilon = 1e-7;\n",
    "    \n",
    "    # Normalization of confusion matrix C\n",
    "    if normalize:\n",
    "        C = C.astype('float') / (epsilon + C.sum(axis=1)[:, newaxis]);\n",
    "\n",
    "    # Print the matrix C\n",
    "    print(C);\n",
    "    \n",
    "    # Image representation\n",
    "    ax = plt.gca();   # <-- grab current axes\n",
    "    C = flipud(C);    # <-- flip horizontally for visualization\n",
    "    im = ax.imshow(C,cmap=cmap);\n",
    "    \n",
    "    # Colorbar\n",
    "    colorbar(im);\n",
    "    \n",
    "    # Title\n",
    "    plt.title(title,fontsize=20,weight=\"bold\");\n",
    "    \n",
    "    # Tick labels\n",
    "    tick_marks = arange(len(classes));\n",
    "    plt.xticks(tick_marks, classes, rotation=45,fontweight=\"bold\");\n",
    "    \n",
    "    # Overwrite default y-axis limits\n",
    "    plt.ylim([-0.5,len(classes)-0.5]);\n",
    "\n",
    "    # Text labels in tiles (i.e., elements)\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = C.max() / 2.\n",
    "    for i, j in iter_prod(range(C.shape[0]), range(C.shape[1])):\n",
    "        plt.text(j, i, format(C[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",weight=\"bold\",\n",
    "                 color=\"white\" if C[i, j] > thresh else \"black\")\n",
    "\n",
    "    # x-axis labels\n",
    "    plt.ylabel('True label',fontsize=16,weight=\"bold\");\n",
    "    \n",
    "    # y-axis labels\n",
    "    plt.xlabel('Predicted label',fontsize=16,weight=\"bold\");\n",
    "    \n",
    "    # Set axis layout\n",
    "    plt.tight_layout();\n",
    "    \n",
    "#########################\n",
    "#    Scale Colorbar:    # - found this online\n",
    "#########################\n",
    "\n",
    "def colorbar(mappable):\n",
    "    last_axes = plt.gca()\n",
    "    ax = mappable.axes\n",
    "    fig = ax.figure\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    cbar = fig.colorbar(mappable, cax=cax)\n",
    "    plt.sca(last_axes)\n",
    "    return cbar\n",
    "\n",
    "#########################\n",
    "#    Visualization:     #\n",
    "#########################\n",
    "\n",
    "conf_fig = plt.figure(figsize=(9.9,9.9));\n",
    "plot_confusion_matrix(\n",
    "    confusion_mat, \n",
    "    classes=[clss for clss in class_table],\n",
    "    normalize=True,\n",
    "    title='Confusion Matrix',\n",
    "    cmap=plt.cm.Greens);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
