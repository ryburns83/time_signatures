{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\textbf{Inferring Musical Time Signature via Apple Watch Logs of Conductor Wrist Motion}$\n",
    "\n",
    "$\\textbf{Author:}\\text{ Ryan Burns}$\n",
    "\n",
    "$\\text{When conducting a chamber group or orchestra, a musical conductor uses a designated baton pattern for each possible time signature a musical}$\n",
    "$\\text{score could be written in. Suppose someone were to wear an Apple Watch on their right wrist while conducting, (assume watch IMU data is}$\n",
    "$\\text{logged at 100 Hz). It is not unreasonable to suspect that we could train a machine learning model to predict the time signature corresponding }$\n",
    "$\\text{to particular wrist motion patterns. A small amount of data is studied to prove this concept using }\\textit{long short-term memory (LSTM)}\\text{ networks.}$\n",
    "$\\text{For a great overview of LSTM and other recurrent units, see: }\\textit{https://colah.github.io/posts/2015-08-Understanding-LSTMs/}\\text{. While intended }$\n",
    "$\\text{for sequential data (e.g., the quasi-cyclostationary wrist motions of a conductor), we also admit that this is a small amount of training and }$\n",
    "$\\text{validation data, so the generalization performance of these models across a variety of conductors, time signatures, and tempos could prove}$\n",
    "$\\text{quite poor. With generalization performance being a concern, we a couple techniques to hopefully mitigate some amount of overfitting. }$\n",
    "\n",
    "$\\text{We add Gaussian noise to the input signals to randomly vary input to the network, in addition to applying random dropout to a subset of}$\n",
    "$\\text{the connections within the network at a fixed probability. The model is trained on a subset of data and validated on the remaining data.}$\n",
    "\n",
    "$\\text{This specific deep learning architecture is comprised of a single convolutional layer fed to a dense hyperbolic tangent layer for feature,}$\n",
    "$\\text{extraction preceding the long short-term memory layer. The LSTM units make use of both types of dropout available (ordinary and recurrent)}$\n",
    "$\\text{as measures to reduce overfitting. A multidimensional sliding window is applied to the accelerometer, gyroscope, and IMU-fused watch}$\n",
    "$\\text{orientation quaternion at the input layer of the network.}$\n",
    "\n",
    "$\\textbf{Motion Class Labels:}$\n",
    "\n",
    "$\\text{All class labels are defined for a right-handed user. An orchestral conductor varies their baton pattern according to 1 of 4 possible states, }$\n",
    "$\\text{comprised of 3 time signature classes and a resting class (i.e., cessation of baton motion).}$\n",
    "\n",
    "$\\text{0 }\\leftrightarrow [1\\enspace0\\enspace0\\enspace0]\\leftrightarrow \\text{REST}\\Longrightarrow\\text{conductor has ceased baton motion (no conducting)}$\n",
    "\n",
    "$\\text{1 }\\leftrightarrow [0\\enspace1\\enspace0\\enspace0]\\leftrightarrow {2/4}\\Longrightarrow\\text{conductor proceeds with baton motion consistent with a }\\mathbf{\\genfrac{}{}{0pt}{}{2}{4}}\\text{ time signature}$\n",
    "\n",
    "$\\text{2 }\\leftrightarrow [0\\enspace0\\enspace1\\enspace0]\\leftrightarrow {3/4}\\Longrightarrow\\text{conductor proceeds with baton motion consistent with a }\\mathbf{\\genfrac{}{}{0pt}{}{3}{4}}\\text{ time signature}$\n",
    "\n",
    "$\\text{3 }\\leftrightarrow [0\\enspace0\\enspace0\\enspace1]\\leftrightarrow {4/4}\\Longrightarrow\\text{conductor proceeds with baton motion consistent with a }\\mathbf{\\genfrac{}{}{0pt}{}{4}{4}}\\text{ time signature}$\n",
    "\n",
    "$\\text{For more information on musical time signatures, visit: }\\textit{https://en.wikipedia.org/wiki/Time_signature}.$\n",
    "\n",
    "![title](baton_motion.png)\n",
    "\n",
    "$\\text{The baton patterns for each time signature of interest are depicted diagramatically above. We assume a tech enthusiast conductor who desires}$\n",
    "$\\text{an Apple Watch app/experience for automatic discrimination between the 3 time signatures above, in addition to a catch-all }\\textit{at-rest}\\text{ state. We }$\n",
    "$\\text{also assume that this conductor would like automatic time-signature inference to be as tempo-agnostic as possible. Be it }\\textit{largo}\\text{ or }\\textit{prestissimo}\\text{,}$\n",
    "$\\text{we assume that the tempo of the musical composition of question would not fool the ideal baton pattern classifier. As such, while the amount}$\n",
    "$\\text{of data collected for this analysis is still limited in its size and diversity (i.e., we can assume overfit models), efforts have been made during}$\n",
    "$\\text{data collection to vary the tempo across each time signature's constituent wrist motion observations. The duration (in seconds or measures)}$\n",
    "$\\text{of each time signature's wrist motion subsequence is also varied during collection. We create an aggregated dataset of independent concatenated}$\n",
    "$\\text{collects for supervised learning in the code below.}$\n",
    "\n",
    "$\\textbf{Note On Labeling:}$\n",
    "\n",
    "$\\text{SensorLog labels are recorded in real time using the app's class label buttons for a streaming iPhone. This iPhone logs data concurrently with}$\n",
    "$\\text{an Apple Watch, which also reports its own class labels. Since toggling of the Apple Watch's class labels using the SensorLog UI on the watch }$\n",
    "$\\text{face would interfere with data collection of wrist motion, we use the }\\textit{iPhone}\\text{ to log wrist motion labels. By time-aligning the iPhone and Apple}$\n",
    "$\\text{Watch streams below (i.e., using POSIX timestamps), we can readily provide wrist motion labels for the Apple Watch motion signals without}$\n",
    "$\\text{interfering with their trajectory as just described. In short, real-time motion labeling is available through dual stream of Apple Watch }$\n",
    "$\\text{iPhone data, where the former provides the motion observations of interest and the latter provides a mechanism for real-time motion labeling.}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\textbf{Import Packages}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import getcwd, environ;\n",
    "from itertools import product as iter_prod;\n",
    "from matplotlib import pyplot as plt;\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from numpy import array, hstack, argmax, ones, zeros, log10;\n",
    "from numpy import logical_or, logical_not, expand_dims, flip;\n",
    "from numpy import  abs, arange, shape, newaxis, sum, flipud;\n",
    "from numpy import nan_to_num;\n",
    "from scipy.signal import parzen;\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model;\n",
    "from tensorflow.keras.optimizers import RMSprop;\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy;\n",
    "from tensorflow.keras.metrics import Precision, Recall, AUC;\n",
    "from tensorflow.keras.layers import Dropout, LSTM, Dense;\n",
    "from tensorflow.keras.layers import Activation, Reshape, Conv1D;\n",
    "from tensorflow.keras.layers import Input, GaussianNoise;\n",
    "from sklearn.metrics import confusion_matrix;\n",
    "\n",
    "from SensorLogUtils import convert_iPhone_units;\n",
    "\n",
    "environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\textbf{Class Label Definitions}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REST</th>\n",
       "      <th>2/4</th>\n",
       "      <th>3/4</th>\n",
       "      <th>4/4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>REST</td>\n",
       "      <td>2/4</td>\n",
       "      <td>3/4</td>\n",
       "      <td>4/4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <td>no conducting / baton pattern</td>\n",
       "      <td>conducting pattern for a 2/4 time signature</td>\n",
       "      <td>conducting pattern for a 3/4 time signature</td>\n",
       "      <td>conducting pattern for a 4/4 time signature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-hot label</th>\n",
       "      <td>[1, 0, 0, 0]</td>\n",
       "      <td>[0, 1, 0, 0]</td>\n",
       "      <td>[0, 0, 1, 0]</td>\n",
       "      <td>[0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ordinal label</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        REST  \\\n",
       "id                                      REST   \n",
       "description    no conducting / baton pattern   \n",
       "1-hot label                     [1, 0, 0, 0]   \n",
       "ordinal label                              0   \n",
       "\n",
       "                                                       2/4  \\\n",
       "id                                                     2/4   \n",
       "description    conducting pattern for a 2/4 time signature   \n",
       "1-hot label                                   [0, 1, 0, 0]   \n",
       "ordinal label                                            1   \n",
       "\n",
       "                                                       3/4  \\\n",
       "id                                                     3/4   \n",
       "description    conducting pattern for a 3/4 time signature   \n",
       "1-hot label                                   [0, 0, 1, 0]   \n",
       "ordinal label                                            2   \n",
       "\n",
       "                                                       4/4  \n",
       "id                                                     4/4  \n",
       "description    conducting pattern for a 4/4 time signature  \n",
       "1-hot label                                   [0, 0, 0, 1]  \n",
       "ordinal label                                            3  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ordinal motion class labels\n",
    "class_table = pd.DataFrame({\n",
    "    'REST': {\n",
    "        'id': 'REST', \n",
    "        'description': 'no conducting / baton pattern',\n",
    "        '1-hot label': [1,0,0,0],\n",
    "        'ordinal label': 0\n",
    "    },\n",
    "    '2/4': {\n",
    "        'id': '2/4', \n",
    "        'description': 'conducting pattern for a 2/4 time signature',\n",
    "        '1-hot label': [0,1,0,0],\n",
    "        'ordinal label': 1\n",
    "    },\n",
    "    '3/4': {\n",
    "        'id': '3/4', \n",
    "        'description':'conducting pattern for a 3/4 time signature',\n",
    "        '1-hot label': [0,0,1,0],\n",
    "        'ordinal label': 2\n",
    "    },\n",
    "    '4/4': {\n",
    "        'id': '4/4', \n",
    "        'description':'conducting pattern for a 4/4 time signature',\n",
    "        '1-hot label': [0,0,0,1],\n",
    "        'ordinal label': 3\n",
    "    }\n",
    "});\n",
    "\n",
    "# Number of classes\n",
    "C = 4;\n",
    "\n",
    "# Print class table\n",
    "class_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\textbf{Specify & Load Dataset}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "# Specify data #\n",
    "################\n",
    "\n",
    "# Specify local data storage path\n",
    "data_path = getcwd() + '/data';\n",
    "\n",
    "# Collect file string ID\n",
    "collect_IDs = [\n",
    "    'time_signatures_collect1',\n",
    "    'time_signatures_collect2'\n",
    "];\n",
    "\n",
    "# Build string filename corresponding to collect_ID\n",
    "collect_files = [\n",
    "    (data_path + '/labeled_' + collect_ID + '_appleWatch.csv')\n",
    "for collect_ID in collect_IDs];\n",
    "\n",
    "#############\n",
    "# Load data #\n",
    "#############\n",
    "\n",
    "# Load and concatenate dataframes for all\n",
    "# labeled collects in list collect_IDs\n",
    "df = pd.concat([pd.read_csv(f, \n",
    "    error_bad_lines=False,\n",
    "    warn_bad_lines=False)\n",
    "    for f in collect_files\n",
    "],axis=0,ignore_index=True);\n",
    "\n",
    "# Data fields (column headers)\n",
    "fields = [fd for fd in df];\n",
    "\n",
    "# Length of dataframe\n",
    "N = len(df); # (samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\textbf{Select IMU Data & 1-Hot Class Labels}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select input signals\n",
    "x = nan_to_num(array(df[[\n",
    "    'accelerometerAccelerationX(m/s^2)',\n",
    "    'accelerometerAccelerationY(m/s^2)',\n",
    "    'accelerometerAccelerationZ(m/s^2)',\n",
    "    'motionRotationRateX(rad/s)',\n",
    "    'motionRotationRateY(rad/s)',\n",
    "    'motionRotationRateZ(rad/s)'\n",
    "]]));\n",
    "\n",
    "# Define 1-hot labels\n",
    "y = nan_to_num(array(df[[\n",
    "    \n",
    "    # List all class headers in table above\n",
    "    class_name for class_name in class_table\n",
    "]]));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\textbf{Specify Sliding Observation Window Parameters}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of raw sensor samples (N)\n",
    "# and their dimensionality (D)\n",
    "N, D = shape(x);\n",
    "\n",
    "# Sliding obs. window length\n",
    "M = 128; # (samples)\n",
    "\n",
    "# Step size of obs. window\n",
    "m = 10;  # (samples)\n",
    "\n",
    "# Linear grid for sliding observation\n",
    "# window reflecting window length & step\n",
    "# size specified above, mapped to raw\n",
    "# sensor samples n = M, M + m, M + 2m, ...\n",
    "obs_idx = [n for n in range(M,N,m)];\n",
    "\n",
    "# Define Parzen window to weight observations\n",
    "w = expand_dims(parzen(M),axis=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\textbf{Define Observations & Class Labels}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Windowed observation sequence input to model\n",
    "X = array([w * x[(n - M):n,:] for n in obs_idx]);\n",
    "\n",
    "# Ground truth 1-hot window-resolution class labels\n",
    "Y = array([\n",
    "    [1 if c == argmax(sum(w * y[(n - M):n,:],0)) \n",
    "    else 0 for c in range(C)] for n in obs_idx]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\textbf{Training Parameters}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fraction of dataset to hold \n",
    "# out for model validation\n",
    "pct_validation = 0.25;\n",
    "\n",
    "# Total number of obs.\n",
    "N_obs = len(X);\n",
    "\n",
    "# Number of training epochs\n",
    "N_epoch = 5000;\n",
    "\n",
    "# Number of batches\n",
    "N_batch = int(N_obs / 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\textbf{Define Machine Learning Model}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 128, 6)]          0         \n",
      "_________________________________________________________________\n",
      "gaussian_noise (GaussianNois (None, 128, 6)            0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 1, 128)            98432     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1, 128)            16512     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 256)               394240    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 510,212\n",
      "Trainable params: 510,212\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#####################################################\n",
    "# Define model architecture w/ Keras functional API #\n",
    "#####################################################\n",
    "\n",
    "# Input layer - M x D observation window\n",
    "input_layer = Input((M,D));\n",
    "\n",
    "# Add Gaussian noise to M x D input\n",
    "h0 = GaussianNoise(5e-3)(input_layer);\n",
    "\n",
    "# Convolutional layer (M x M)\n",
    "h1 = Conv1D(M,M,activation='relu')(h0);\n",
    "\n",
    "# Dense hyperbolic tangent activation layer\n",
    "h2 = Dense(M,activation='tanh')(h1);\n",
    "\n",
    "# Long short-term memory layer\n",
    "h3 = LSTM(2 * M,activation='tanh',\n",
    "    dropout=0.5,\n",
    "    recurrent_dropout=0.5)(h2);\n",
    "\n",
    "# Output layer - C x 1 softmax class activation \n",
    "output_layer = Dense(C,activation='softmax')(h3);\n",
    "\n",
    "# Set up Keras Model() instance\n",
    "model = Model(\n",
    "    inputs=input_layer,  # Model inputs\n",
    "    outputs=output_layer # Model outputs\n",
    ");\n",
    "\n",
    "###########################\n",
    "# Define loss & optimizer #\n",
    "###########################\n",
    "\n",
    "# Set RMSprop optimization for \n",
    "# speed-of-convergence purposes\n",
    "opt = RMSprop(\n",
    "    learning_rate=0.001,\n",
    "    rho=0.9,\n",
    "    momentum=0.001,\n",
    "    epsilon=1e-07,\n",
    "    name=\"RMSprop\"\n",
    ");\n",
    "\n",
    "# Model compilation, using categorical\n",
    "# cross-entropy error w/ RMSprop\n",
    "model.compile(\n",
    "    \n",
    "    # Error/loss function\n",
    "    loss='categorical_crossentropy', \n",
    "    \n",
    "    # Use RMSprop\n",
    "    optimizer=opt,\n",
    "    \n",
    "    # List metrics here\n",
    "    metrics=[\n",
    "        CategoricalAccuracy(),\n",
    "        AUC(),\n",
    "        Precision(),\n",
    "        Recall()\n",
    "    ]\n",
    ");\n",
    "\n",
    "# Print a summary table\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\textbf{Train Machine Learning Model}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6156 samples, validate on 2052 samples\n",
      "Epoch 1/5000\n",
      "6156/6156 [==============================] - 4s 727us/sample - loss: 1.3903 - categorical_accuracy: 0.2437 - auc: 0.5061 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.2758 - val_categorical_accuracy: 0.3743 - val_auc: 0.6907 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/5000\n",
      "6156/6156 [==============================] - 1s 110us/sample - loss: 1.3341 - categorical_accuracy: 0.3129 - auc: 0.6302 - precision: 0.5000 - recall: 6.4977e-04 - val_loss: 1.2385 - val_categorical_accuracy: 0.4113 - val_auc: 0.7220 - val_precision: 0.9231 - val_recall: 0.0234\n",
      "Epoch 3/5000\n",
      "6156/6156 [==============================] - 1s 106us/sample - loss: 1.2572 - categorical_accuracy: 0.4285 - auc: 0.7024 - precision: 0.6689 - recall: 0.0328 - val_loss: 1.1638 - val_categorical_accuracy: 0.4737 - val_auc: 0.7896 - val_precision: 0.7324 - val_recall: 0.0253\n",
      "Epoch 4/5000\n",
      "6156/6156 [==============================] - 1s 104us/sample - loss: 1.2002 - categorical_accuracy: 0.4623 - auc: 0.7587 - precision: 0.5724 - recall: 0.0141 - val_loss: 1.1038 - val_categorical_accuracy: 0.4903 - val_auc: 0.7845 - val_precision: 0.6228 - val_recall: 0.2558\n",
      "Epoch 5/5000\n",
      "6156/6156 [==============================] - 1s 103us/sample - loss: 1.1797 - categorical_accuracy: 0.4643 - auc: 0.7408 - precision: 0.6028 - recall: 0.2329 - val_loss: 1.2640 - val_categorical_accuracy: 0.3017 - val_auc: 0.6765 - val_precision: 0.4482 - val_recall: 0.0970\n",
      "Epoch 6/5000\n",
      "6156/6156 [==============================] - 1s 103us/sample - loss: 1.2065 - categorical_accuracy: 0.4224 - auc: 0.7258 - precision: 0.6819 - recall: 0.1212 - val_loss: 0.9589 - val_categorical_accuracy: 0.5824 - val_auc: 0.8624 - val_precision: 0.7910 - val_recall: 0.3246\n",
      "Epoch 7/5000\n",
      "6156/6156 [==============================] - 1s 105us/sample - loss: 1.0554 - categorical_accuracy: 0.5219 - auc: 0.8141 - precision: 0.7836 - recall: 0.2494 - val_loss: 0.9411 - val_categorical_accuracy: 0.6574 - val_auc: 0.8792 - val_precision: 0.9179 - val_recall: 0.3431\n",
      "Epoch 8/5000\n",
      "6156/6156 [==============================] - 1s 107us/sample - loss: 0.9378 - categorical_accuracy: 0.6827 - auc: 0.8935 - precision: 0.9375 - recall: 0.3044 - val_loss: 0.7860 - val_categorical_accuracy: 0.7281 - val_auc: 0.9219 - val_precision: 0.8556 - val_recall: 0.4620\n",
      "Epoch 9/5000\n",
      "6156/6156 [==============================] - 1s 106us/sample - loss: 0.8610 - categorical_accuracy: 0.6655 - auc: 0.9010 - precision: 0.8386 - recall: 0.3774 - val_loss: 0.8370 - val_categorical_accuracy: 0.6686 - val_auc: 0.8919 - val_precision: 0.7872 - val_recall: 0.4254\n",
      "Epoch 10/5000\n",
      "6156/6156 [==============================] - 1s 103us/sample - loss: 0.8012 - categorical_accuracy: 0.7232 - auc: 0.9202 - precision: 0.8785 - recall: 0.4630 - val_loss: 0.6773 - val_categorical_accuracy: 0.7485 - val_auc: 0.9369 - val_precision: 0.8435 - val_recall: 0.5989\n",
      "Epoch 11/5000\n",
      "6156/6156 [==============================] - 1s 104us/sample - loss: 0.7588 - categorical_accuracy: 0.7060 - auc: 0.9173 - precision: 0.8251 - recall: 0.5128 - val_loss: 0.7994 - val_categorical_accuracy: 0.6633 - val_auc: 0.8943 - val_precision: 0.7480 - val_recall: 0.5078\n",
      "Epoch 12/5000\n",
      "6156/6156 [==============================] - 1s 104us/sample - loss: 0.7205 - categorical_accuracy: 0.7377 - auc: 0.9296 - precision: 0.8495 - recall: 0.5604 - val_loss: 0.6102 - val_categorical_accuracy: 0.7690 - val_auc: 0.9448 - val_precision: 0.8455 - val_recall: 0.6827\n",
      "Epoch 13/5000\n",
      "6156/6156 [==============================] - 1s 109us/sample - loss: 0.7037 - categorical_accuracy: 0.7130 - auc: 0.9221 - precision: 0.7983 - recall: 0.5858 - val_loss: 0.7330 - val_categorical_accuracy: 0.6866 - val_auc: 0.9164 - val_precision: 0.7726 - val_recall: 0.6028\n",
      "Epoch 14/5000\n",
      "6156/6156 [==============================] - 1s 111us/sample - loss: 0.6740 - categorical_accuracy: 0.7571 - auc: 0.9393 - precision: 0.8312 - recall: 0.6329 - val_loss: 0.6233 - val_categorical_accuracy: 0.7675 - val_auc: 0.9376 - val_precision: 0.8203 - val_recall: 0.6540\n",
      "Epoch 15/5000\n",
      "6156/6156 [==============================] - 1s 109us/sample - loss: 0.6413 - categorical_accuracy: 0.7386 - auc: 0.9346 - precision: 0.8059 - recall: 0.6470 - val_loss: 0.5996 - val_categorical_accuracy: 0.7607 - val_auc: 0.9440 - val_precision: 0.8034 - val_recall: 0.6930\n",
      "Epoch 16/5000\n",
      "6156/6156 [==============================] - 1s 107us/sample - loss: 0.5678 - categorical_accuracy: 0.7994 - auc: 0.9551 - precision: 0.8511 - recall: 0.7310 - val_loss: 0.5380 - val_categorical_accuracy: 0.8085 - val_auc: 0.9550 - val_precision: 0.8635 - val_recall: 0.7242\n",
      "Epoch 17/5000\n",
      "6156/6156 [==============================] - 1s 109us/sample - loss: 0.5106 - categorical_accuracy: 0.8077 - auc: 0.9612 - precision: 0.8568 - recall: 0.7419 - val_loss: 0.4921 - val_categorical_accuracy: 0.7909 - val_auc: 0.9611 - val_precision: 0.8364 - val_recall: 0.7476\n",
      "Epoch 18/5000\n",
      "6156/6156 [==============================] - 1s 109us/sample - loss: 0.4814 - categorical_accuracy: 0.8233 - auc: 0.9660 - precision: 0.8600 - recall: 0.7763 - val_loss: 0.5350 - val_categorical_accuracy: 0.7861 - val_auc: 0.9521 - val_precision: 0.8369 - val_recall: 0.7427\n",
      "Epoch 19/5000\n",
      "6156/6156 [==============================] - 1s 110us/sample - loss: 0.4763 - categorical_accuracy: 0.8111 - auc: 0.9635 - precision: 0.8453 - recall: 0.7706 - val_loss: 0.4952 - val_categorical_accuracy: 0.7797 - val_auc: 0.9580 - val_precision: 0.8098 - val_recall: 0.7490\n",
      "Epoch 20/5000\n",
      "6156/6156 [==============================] - 1s 108us/sample - loss: 0.4813 - categorical_accuracy: 0.8119 - auc: 0.9621 - precision: 0.8361 - recall: 0.7739 - val_loss: 0.5328 - val_categorical_accuracy: 0.7675 - val_auc: 0.9510 - val_precision: 0.8090 - val_recall: 0.7368\n",
      "Epoch 21/5000\n",
      "6156/6156 [==============================] - 1s 108us/sample - loss: 0.4824 - categorical_accuracy: 0.7932 - auc: 0.9606 - precision: 0.8185 - recall: 0.7646 - val_loss: 0.5045 - val_categorical_accuracy: 0.7744 - val_auc: 0.9560 - val_precision: 0.7983 - val_recall: 0.7427\n",
      "Epoch 22/5000\n",
      "6156/6156 [==============================] - 1s 108us/sample - loss: 0.4527 - categorical_accuracy: 0.8190 - auc: 0.9656 - precision: 0.8417 - recall: 0.7844 - val_loss: 0.4410 - val_categorical_accuracy: 0.8294 - val_auc: 0.9664 - val_precision: 0.8546 - val_recall: 0.7963\n",
      "Epoch 23/5000\n",
      "6156/6156 [==============================] - 1s 109us/sample - loss: 0.4371 - categorical_accuracy: 0.8111 - auc: 0.9669 - precision: 0.8291 - recall: 0.7904 - val_loss: 0.5949 - val_categorical_accuracy: 0.7393 - val_auc: 0.9404 - val_precision: 0.7611 - val_recall: 0.7018\n",
      "Epoch 24/5000\n",
      "6156/6156 [==============================] - 1s 107us/sample - loss: 0.4623 - categorical_accuracy: 0.8078 - auc: 0.9634 - precision: 0.8331 - recall: 0.7831 - val_loss: 0.4194 - val_categorical_accuracy: 0.8484 - val_auc: 0.9697 - val_precision: 0.8657 - val_recall: 0.8231\n",
      "Epoch 25/5000\n",
      "6156/6156 [==============================] - 1s 113us/sample - loss: 0.4735 - categorical_accuracy: 0.7976 - auc: 0.9604 - precision: 0.8164 - recall: 0.7760 - val_loss: 0.6598 - val_categorical_accuracy: 0.7047 - val_auc: 0.9288 - val_precision: 0.7413 - val_recall: 0.6813\n",
      "Epoch 26/5000\n",
      "6156/6156 [==============================] - 1s 109us/sample - loss: 0.4863 - categorical_accuracy: 0.8031 - auc: 0.9586 - precision: 0.8288 - recall: 0.7701 - val_loss: 0.3781 - val_categorical_accuracy: 0.8947 - val_auc: 0.9787 - val_precision: 0.9147 - val_recall: 0.8728\n",
      "Epoch 27/5000\n",
      "6156/6156 [==============================] - 1s 108us/sample - loss: 0.3923 - categorical_accuracy: 0.8596 - auc: 0.9757 - precision: 0.8822 - recall: 0.8356 - val_loss: 0.4180 - val_categorical_accuracy: 0.8528 - val_auc: 0.9702 - val_precision: 0.8760 - val_recall: 0.8124\n",
      "Epoch 28/5000\n",
      "6156/6156 [==============================] - 1s 109us/sample - loss: 0.3634 - categorical_accuracy: 0.8671 - auc: 0.9781 - precision: 0.8881 - recall: 0.8431 - val_loss: 0.3601 - val_categorical_accuracy: 0.8918 - val_auc: 0.9786 - val_precision: 0.9096 - val_recall: 0.8728\n",
      "Epoch 29/5000\n",
      "6156/6156 [==============================] - 1s 108us/sample - loss: 0.3403 - categorical_accuracy: 0.8801 - auc: 0.9812 - precision: 0.8938 - recall: 0.8631 - val_loss: 0.3798 - val_categorical_accuracy: 0.8665 - val_auc: 0.9747 - val_precision: 0.8861 - val_recall: 0.8455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/5000\n",
      "6156/6156 [==============================] - 1s 110us/sample - loss: 0.3242 - categorical_accuracy: 0.8809 - auc: 0.9827 - precision: 0.8960 - recall: 0.8660 - val_loss: 0.3563 - val_categorical_accuracy: 0.8855 - val_auc: 0.9783 - val_precision: 0.9053 - val_recall: 0.8670\n",
      "Epoch 31/5000\n",
      "6156/6156 [==============================] - 1s 110us/sample - loss: 0.3374 - categorical_accuracy: 0.8663 - auc: 0.9801 - precision: 0.8828 - recall: 0.8489 - val_loss: 0.5201 - val_categorical_accuracy: 0.7817 - val_auc: 0.9588 - val_precision: 0.7922 - val_recall: 0.7749\n",
      "Epoch 32/5000\n",
      "6156/6156 [==============================] - 1s 109us/sample - loss: 0.4255 - categorical_accuracy: 0.8294 - auc: 0.9684 - precision: 0.8403 - recall: 0.8147 - val_loss: 0.4677 - val_categorical_accuracy: 0.8124 - val_auc: 0.9630 - val_precision: 0.8249 - val_recall: 0.8012\n",
      "Epoch 33/5000\n",
      "6156/6156 [==============================] - 1s 109us/sample - loss: 0.4556 - categorical_accuracy: 0.8083 - auc: 0.9658 - precision: 0.8216 - recall: 0.7974 - val_loss: 0.5075 - val_categorical_accuracy: 0.7792 - val_auc: 0.9565 - val_precision: 0.7859 - val_recall: 0.7583\n",
      "Epoch 34/5000\n",
      "6156/6156 [==============================] - 1s 107us/sample - loss: 0.4192 - categorical_accuracy: 0.8164 - auc: 0.9694 - precision: 0.8288 - recall: 0.8030 - val_loss: 0.3825 - val_categorical_accuracy: 0.8772 - val_auc: 0.9746 - val_precision: 0.8949 - val_recall: 0.8548\n",
      "Epoch 35/5000\n",
      "6156/6156 [==============================] - 1s 107us/sample - loss: 0.3469 - categorical_accuracy: 0.8567 - auc: 0.9787 - precision: 0.8719 - recall: 0.8411 - val_loss: 0.3739 - val_categorical_accuracy: 0.8567 - val_auc: 0.9748 - val_precision: 0.8729 - val_recall: 0.8436\n",
      "Epoch 36/5000\n",
      "6156/6156 [==============================] - 1s 108us/sample - loss: 0.3116 - categorical_accuracy: 0.8798 - auc: 0.9832 - precision: 0.8937 - recall: 0.8670 - val_loss: 0.3413 - val_categorical_accuracy: 0.8977 - val_auc: 0.9800 - val_precision: 0.9152 - val_recall: 0.8840\n",
      "Epoch 37/5000\n",
      "6156/6156 [==============================] - 1s 110us/sample - loss: 0.2990 - categorical_accuracy: 0.8865 - auc: 0.9848 - precision: 0.9000 - recall: 0.8715 - val_loss: 0.3646 - val_categorical_accuracy: 0.8655 - val_auc: 0.9762 - val_precision: 0.8826 - val_recall: 0.8533\n",
      "Epoch 38/5000\n",
      "6156/6156 [==============================] - 1s 108us/sample - loss: 0.2945 - categorical_accuracy: 0.8879 - auc: 0.9850 - precision: 0.9014 - recall: 0.8757 - val_loss: 0.3307 - val_categorical_accuracy: 0.8952 - val_auc: 0.9808 - val_precision: 0.9113 - val_recall: 0.8816\n",
      "Epoch 39/5000\n",
      "6156/6156 [==============================] - 1s 107us/sample - loss: 0.2949 - categorical_accuracy: 0.8826 - auc: 0.9847 - precision: 0.8937 - recall: 0.8717 - val_loss: 0.4371 - val_categorical_accuracy: 0.8177 - val_auc: 0.9668 - val_precision: 0.8293 - val_recall: 0.8075\n",
      "Epoch 40/5000\n",
      "6156/6156 [==============================] - 1s 109us/sample - loss: 0.3323 - categorical_accuracy: 0.8678 - auc: 0.9799 - precision: 0.8805 - recall: 0.8561 - val_loss: 0.3552 - val_categorical_accuracy: 0.8665 - val_auc: 0.9768 - val_precision: 0.8740 - val_recall: 0.8587\n",
      "Epoch 41/5000\n",
      "6156/6156 [==============================] - 1s 108us/sample - loss: 0.3457 - categorical_accuracy: 0.8491 - auc: 0.9783 - precision: 0.8569 - recall: 0.8411 - val_loss: 0.5458 - val_categorical_accuracy: 0.7753 - val_auc: 0.9532 - val_precision: 0.7891 - val_recall: 0.7602\n",
      "Epoch 42/5000\n",
      "6156/6156 [==============================] - 1s 109us/sample - loss: 0.3995 - categorical_accuracy: 0.8341 - auc: 0.9723 - precision: 0.8459 - recall: 0.8186 - val_loss: 0.3353 - val_categorical_accuracy: 0.8908 - val_auc: 0.9800 - val_precision: 0.9025 - val_recall: 0.8840\n",
      "Epoch 43/5000\n",
      "6156/6156 [==============================] - 1s 110us/sample - loss: 0.3035 - categorical_accuracy: 0.8756 - auc: 0.9837 - precision: 0.8839 - recall: 0.8678 - val_loss: 0.3677 - val_categorical_accuracy: 0.8494 - val_auc: 0.9756 - val_precision: 0.8616 - val_recall: 0.8431\n",
      "Epoch 44/5000\n",
      "6156/6156 [==============================] - 1s 108us/sample - loss: 0.2867 - categorical_accuracy: 0.8882 - auc: 0.9850 - precision: 0.8975 - recall: 0.8795 - val_loss: 0.3224 - val_categorical_accuracy: 0.8972 - val_auc: 0.9815 - val_precision: 0.9117 - val_recall: 0.8860\n",
      "Epoch 45/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.2776 - categorical_accuracy: 0.8865 - auc: 0.9861 - precision: 0.8958 - recall: 0.8757 - val_loss: 0.3949 - val_categorical_accuracy: 0.8338 - val_auc: 0.9734 - val_precision: 0.8410 - val_recall: 0.8250\n",
      "Epoch 46/5000\n",
      "6156/6156 [==============================] - 1s 115us/sample - loss: 0.3022 - categorical_accuracy: 0.8787 - auc: 0.9835 - precision: 0.8867 - recall: 0.8696 - val_loss: 0.3839 - val_categorical_accuracy: 0.8533 - val_auc: 0.9741 - val_precision: 0.8694 - val_recall: 0.8367\n",
      "Epoch 47/5000\n",
      "6156/6156 [==============================] - 1s 116us/sample - loss: 0.3362 - categorical_accuracy: 0.8562 - auc: 0.9797 - precision: 0.8691 - recall: 0.8426 - val_loss: 0.4567 - val_categorical_accuracy: 0.8036 - val_auc: 0.9663 - val_precision: 0.8133 - val_recall: 0.7963\n",
      "Epoch 48/5000\n",
      "6156/6156 [==============================] - 1s 116us/sample - loss: 0.3721 - categorical_accuracy: 0.8434 - auc: 0.9756 - precision: 0.8522 - recall: 0.8346 - val_loss: 0.4189 - val_categorical_accuracy: 0.8596 - val_auc: 0.9697 - val_precision: 0.8758 - val_recall: 0.8348\n",
      "Epoch 49/5000\n",
      "6156/6156 [==============================] - 1s 120us/sample - loss: 0.3449 - categorical_accuracy: 0.8577 - auc: 0.9781 - precision: 0.8750 - recall: 0.8450 - val_loss: 0.3308 - val_categorical_accuracy: 0.8879 - val_auc: 0.9792 - val_precision: 0.8978 - val_recall: 0.8772\n",
      "Epoch 50/5000\n",
      "6156/6156 [==============================] - 1s 114us/sample - loss: 0.2774 - categorical_accuracy: 0.8944 - auc: 0.9863 - precision: 0.9044 - recall: 0.8865 - val_loss: 0.3521 - val_categorical_accuracy: 0.8860 - val_auc: 0.9779 - val_precision: 0.8982 - val_recall: 0.8772\n",
      "Epoch 51/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.2617 - categorical_accuracy: 0.9014 - auc: 0.9879 - precision: 0.9094 - recall: 0.8938 - val_loss: 0.3060 - val_categorical_accuracy: 0.9035 - val_auc: 0.9815 - val_precision: 0.9132 - val_recall: 0.8967\n",
      "Epoch 52/5000\n",
      "6156/6156 [==============================] - 1s 110us/sample - loss: 0.2550 - categorical_accuracy: 0.9061 - auc: 0.9880 - precision: 0.9137 - recall: 0.8998 - val_loss: 0.3608 - val_categorical_accuracy: 0.8767 - val_auc: 0.9768 - val_precision: 0.8859 - val_recall: 0.8704\n",
      "Epoch 53/5000\n",
      "6156/6156 [==============================] - 1s 109us/sample - loss: 0.2568 - categorical_accuracy: 0.9068 - auc: 0.9881 - precision: 0.9164 - recall: 0.8993 - val_loss: 0.2992 - val_categorical_accuracy: 0.9055 - val_auc: 0.9820 - val_precision: 0.9156 - val_recall: 0.8991\n",
      "Epoch 54/5000\n",
      "6156/6156 [==============================] - 1s 109us/sample - loss: 0.2503 - categorical_accuracy: 0.9066 - auc: 0.9884 - precision: 0.9134 - recall: 0.8983 - val_loss: 0.3759 - val_categorical_accuracy: 0.8548 - val_auc: 0.9765 - val_precision: 0.8659 - val_recall: 0.8494\n",
      "Epoch 55/5000\n",
      "6156/6156 [==============================] - 1s 110us/sample - loss: 0.2593 - categorical_accuracy: 0.8954 - auc: 0.9878 - precision: 0.9036 - recall: 0.8889 - val_loss: 0.3381 - val_categorical_accuracy: 0.8572 - val_auc: 0.9781 - val_precision: 0.8658 - val_recall: 0.8523\n",
      "Epoch 56/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.2906 - categorical_accuracy: 0.8715 - auc: 0.9848 - precision: 0.8791 - recall: 0.8655 - val_loss: 0.5139 - val_categorical_accuracy: 0.7992 - val_auc: 0.9639 - val_precision: 0.8094 - val_recall: 0.7904\n",
      "Epoch 57/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.3729 - categorical_accuracy: 0.8468 - auc: 0.9777 - precision: 0.8532 - recall: 0.8384 - val_loss: 0.3371 - val_categorical_accuracy: 0.8855 - val_auc: 0.9795 - val_precision: 0.8921 - val_recall: 0.8782\n",
      "Epoch 58/5000\n",
      "6156/6156 [==============================] - 1s 111us/sample - loss: 0.2845 - categorical_accuracy: 0.8830 - auc: 0.9850 - precision: 0.8880 - recall: 0.8772 - val_loss: 0.3700 - val_categorical_accuracy: 0.8504 - val_auc: 0.9751 - val_precision: 0.8608 - val_recall: 0.8406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/5000\n",
      "6156/6156 [==============================] - 1s 110us/sample - loss: 0.2701 - categorical_accuracy: 0.8929 - auc: 0.9864 - precision: 0.9034 - recall: 0.8843 - val_loss: 0.3203 - val_categorical_accuracy: 0.9050 - val_auc: 0.9822 - val_precision: 0.9136 - val_recall: 0.8972\n",
      "Epoch 60/5000\n",
      "6156/6156 [==============================] - 1s 109us/sample - loss: 0.2453 - categorical_accuracy: 0.9064 - auc: 0.9892 - precision: 0.9135 - recall: 0.8986 - val_loss: 0.3361 - val_categorical_accuracy: 0.8752 - val_auc: 0.9785 - val_precision: 0.8871 - val_recall: 0.8655\n",
      "Epoch 61/5000\n",
      "6156/6156 [==============================] - 1s 110us/sample - loss: 0.2373 - categorical_accuracy: 0.9113 - auc: 0.9889 - precision: 0.9184 - recall: 0.9032 - val_loss: 0.3049 - val_categorical_accuracy: 0.9108 - val_auc: 0.9836 - val_precision: 0.9157 - val_recall: 0.9050\n",
      "Epoch 62/5000\n",
      "6156/6156 [==============================] - 1s 110us/sample - loss: 0.2281 - categorical_accuracy: 0.9116 - auc: 0.9905 - precision: 0.9180 - recall: 0.9058 - val_loss: 0.3436 - val_categorical_accuracy: 0.8713 - val_auc: 0.9782 - val_precision: 0.8782 - val_recall: 0.8640\n",
      "Epoch 63/5000\n",
      "6156/6156 [==============================] - 1s 110us/sample - loss: 0.2347 - categorical_accuracy: 0.9089 - auc: 0.9897 - precision: 0.9160 - recall: 0.9037 - val_loss: 0.3017 - val_categorical_accuracy: 0.8977 - val_auc: 0.9824 - val_precision: 0.9053 - val_recall: 0.8899\n",
      "Epoch 64/5000\n",
      "6156/6156 [==============================] - 1s 111us/sample - loss: 0.2346 - categorical_accuracy: 0.8978 - auc: 0.9897 - precision: 0.9034 - recall: 0.8933 - val_loss: 0.4386 - val_categorical_accuracy: 0.8216 - val_auc: 0.9705 - val_precision: 0.8306 - val_recall: 0.8148\n",
      "Epoch 65/5000\n",
      "6156/6156 [==============================] - 1s 110us/sample - loss: 0.2910 - categorical_accuracy: 0.8778 - auc: 0.9850 - precision: 0.8843 - recall: 0.8752 - val_loss: 0.3248 - val_categorical_accuracy: 0.8826 - val_auc: 0.9799 - val_precision: 0.8940 - val_recall: 0.8757\n",
      "Epoch 66/5000\n",
      "6156/6156 [==============================] - 1s 110us/sample - loss: 0.2727 - categorical_accuracy: 0.8860 - auc: 0.9861 - precision: 0.8941 - recall: 0.8791 - val_loss: 0.3974 - val_categorical_accuracy: 0.8436 - val_auc: 0.9736 - val_precision: 0.8479 - val_recall: 0.8397\n",
      "Epoch 67/5000\n",
      "6156/6156 [==============================] - 1s 111us/sample - loss: 0.2640 - categorical_accuracy: 0.8895 - auc: 0.9873 - precision: 0.8959 - recall: 0.8837 - val_loss: 0.3113 - val_categorical_accuracy: 0.8991 - val_auc: 0.9816 - val_precision: 0.9104 - val_recall: 0.8918\n",
      "Epoch 68/5000\n",
      "6156/6156 [==============================] - 1s 111us/sample - loss: 0.2410 - categorical_accuracy: 0.9035 - auc: 0.9890 - precision: 0.9128 - recall: 0.8962 - val_loss: 0.3405 - val_categorical_accuracy: 0.8704 - val_auc: 0.9787 - val_precision: 0.8755 - val_recall: 0.8670\n",
      "Epoch 69/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.2296 - categorical_accuracy: 0.9082 - auc: 0.9904 - precision: 0.9145 - recall: 0.9055 - val_loss: 0.3046 - val_categorical_accuracy: 0.9069 - val_auc: 0.9822 - val_precision: 0.9175 - val_recall: 0.9001\n",
      "Epoch 70/5000\n",
      "6156/6156 [==============================] - 1s 111us/sample - loss: 0.2159 - categorical_accuracy: 0.9173 - auc: 0.9913 - precision: 0.9246 - recall: 0.9107 - val_loss: 0.3274 - val_categorical_accuracy: 0.8845 - val_auc: 0.9799 - val_precision: 0.8909 - val_recall: 0.8830\n",
      "Epoch 71/5000\n",
      "6156/6156 [==============================] - 1s 111us/sample - loss: 0.2204 - categorical_accuracy: 0.9189 - auc: 0.9910 - precision: 0.9245 - recall: 0.9115 - val_loss: 0.3525 - val_categorical_accuracy: 0.8923 - val_auc: 0.9769 - val_precision: 0.9013 - val_recall: 0.8816\n",
      "Epoch 72/5000\n",
      "6156/6156 [==============================] - 1s 110us/sample - loss: 0.2354 - categorical_accuracy: 0.9137 - auc: 0.9894 - precision: 0.9214 - recall: 0.9063 - val_loss: 0.3661 - val_categorical_accuracy: 0.8772 - val_auc: 0.9751 - val_precision: 0.8844 - val_recall: 0.8728\n",
      "Epoch 73/5000\n",
      "6156/6156 [==============================] - 1s 111us/sample - loss: 0.2977 - categorical_accuracy: 0.8892 - auc: 0.9840 - precision: 0.8998 - recall: 0.8824 - val_loss: 0.6415 - val_categorical_accuracy: 0.7890 - val_auc: 0.9413 - val_precision: 0.7966 - val_recall: 0.7827\n",
      "Epoch 74/5000\n",
      "6156/6156 [==============================] - 1s 111us/sample - loss: 0.4050 - categorical_accuracy: 0.8611 - auc: 0.9687 - precision: 0.8731 - recall: 0.8502 - val_loss: 0.3514 - val_categorical_accuracy: 0.8938 - val_auc: 0.9766 - val_precision: 0.9007 - val_recall: 0.8884\n",
      "Epoch 75/5000\n",
      "6156/6156 [==============================] - 1s 109us/sample - loss: 0.3337 - categorical_accuracy: 0.8780 - auc: 0.9794 - precision: 0.8894 - recall: 0.8686 - val_loss: 0.3330 - val_categorical_accuracy: 0.8942 - val_auc: 0.9803 - val_precision: 0.9005 - val_recall: 0.8913\n",
      "Epoch 76/5000\n",
      "6156/6156 [==============================] - 1s 111us/sample - loss: 0.2195 - categorical_accuracy: 0.9206 - auc: 0.9911 - precision: 0.9262 - recall: 0.9157 - val_loss: 0.2806 - val_categorical_accuracy: 0.9137 - val_auc: 0.9843 - val_precision: 0.9218 - val_recall: 0.9074\n",
      "Epoch 77/5000\n",
      "6156/6156 [==============================] - 1s 109us/sample - loss: 0.1948 - categorical_accuracy: 0.9292 - auc: 0.9928 - precision: 0.9352 - recall: 0.9254 - val_loss: 0.3153 - val_categorical_accuracy: 0.8957 - val_auc: 0.9809 - val_precision: 0.9029 - val_recall: 0.8928\n",
      "Epoch 78/5000\n",
      "6156/6156 [==============================] - 1s 111us/sample - loss: 0.1960 - categorical_accuracy: 0.9246 - auc: 0.9930 - precision: 0.9295 - recall: 0.9211 - val_loss: 0.2801 - val_categorical_accuracy: 0.9108 - val_auc: 0.9840 - val_precision: 0.9140 - val_recall: 0.9064\n",
      "Epoch 79/5000\n",
      "6156/6156 [==============================] - 1s 109us/sample - loss: 0.1890 - categorical_accuracy: 0.9250 - auc: 0.9933 - precision: 0.9294 - recall: 0.9217 - val_loss: 0.3565 - val_categorical_accuracy: 0.8723 - val_auc: 0.9789 - val_precision: 0.8788 - val_recall: 0.8660\n",
      "Epoch 80/5000\n",
      "6156/6156 [==============================] - 1s 111us/sample - loss: 0.2143 - categorical_accuracy: 0.9146 - auc: 0.9914 - precision: 0.9190 - recall: 0.9102 - val_loss: 0.3484 - val_categorical_accuracy: 0.8616 - val_auc: 0.9796 - val_precision: 0.8666 - val_recall: 0.8582\n",
      "Epoch 81/5000\n",
      "6156/6156 [==============================] - 1s 109us/sample - loss: 0.2709 - categorical_accuracy: 0.8801 - auc: 0.9874 - precision: 0.8851 - recall: 0.8774 - val_loss: 0.5506 - val_categorical_accuracy: 0.7968 - val_auc: 0.9639 - val_precision: 0.8006 - val_recall: 0.7904\n",
      "Epoch 82/5000\n",
      "6156/6156 [==============================] - 1s 111us/sample - loss: 0.3717 - categorical_accuracy: 0.8564 - auc: 0.9788 - precision: 0.8611 - recall: 0.8530 - val_loss: 0.2987 - val_categorical_accuracy: 0.9064 - val_auc: 0.9836 - val_precision: 0.9127 - val_recall: 0.9020\n",
      "Epoch 83/5000\n",
      "6156/6156 [==============================] - 1s 111us/sample - loss: 0.2280 - categorical_accuracy: 0.9095 - auc: 0.9904 - precision: 0.9139 - recall: 0.9053 - val_loss: 0.3239 - val_categorical_accuracy: 0.8874 - val_auc: 0.9804 - val_precision: 0.8933 - val_recall: 0.8811\n",
      "Epoch 84/5000\n",
      "6156/6156 [==============================] - 1s 113us/sample - loss: 0.1993 - categorical_accuracy: 0.9233 - auc: 0.9926 - precision: 0.9295 - recall: 0.9189 - val_loss: 0.2842 - val_categorical_accuracy: 0.9157 - val_auc: 0.9841 - val_precision: 0.9207 - val_recall: 0.9113\n",
      "Epoch 85/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.1822 - categorical_accuracy: 0.9362 - auc: 0.9941 - precision: 0.9418 - recall: 0.9308 - val_loss: 0.2923 - val_categorical_accuracy: 0.9074 - val_auc: 0.9834 - val_precision: 0.9121 - val_recall: 0.9006\n",
      "Epoch 86/5000\n",
      "6156/6156 [==============================] - 1s 111us/sample - loss: 0.1736 - categorical_accuracy: 0.9397 - auc: 0.9943 - precision: 0.9446 - recall: 0.9357 - val_loss: 0.2815 - val_categorical_accuracy: 0.9157 - val_auc: 0.9843 - val_precision: 0.9216 - val_recall: 0.9103\n",
      "Epoch 87/5000\n",
      "6156/6156 [==============================] - 1s 111us/sample - loss: 0.1702 - categorical_accuracy: 0.9399 - auc: 0.9947 - precision: 0.9458 - recall: 0.9362 - val_loss: 0.3028 - val_categorical_accuracy: 0.9045 - val_auc: 0.9824 - val_precision: 0.9096 - val_recall: 0.8977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.1697 - categorical_accuracy: 0.9383 - auc: 0.9946 - precision: 0.9436 - recall: 0.9329 - val_loss: 0.2823 - val_categorical_accuracy: 0.9147 - val_auc: 0.9839 - val_precision: 0.9197 - val_recall: 0.9094\n",
      "Epoch 89/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.1779 - categorical_accuracy: 0.9277 - auc: 0.9940 - precision: 0.9327 - recall: 0.9253 - val_loss: 0.3625 - val_categorical_accuracy: 0.8679 - val_auc: 0.9784 - val_precision: 0.8727 - val_recall: 0.8655\n",
      "Epoch 90/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.1991 - categorical_accuracy: 0.9172 - auc: 0.9925 - precision: 0.9218 - recall: 0.9139 - val_loss: 0.3299 - val_categorical_accuracy: 0.8748 - val_auc: 0.9807 - val_precision: 0.8802 - val_recall: 0.8699\n",
      "Epoch 91/5000\n",
      "6156/6156 [==============================] - 1s 110us/sample - loss: 0.2561 - categorical_accuracy: 0.8871 - auc: 0.9884 - precision: 0.8915 - recall: 0.8847 - val_loss: 0.5269 - val_categorical_accuracy: 0.8070 - val_auc: 0.9649 - val_precision: 0.8142 - val_recall: 0.8031\n",
      "Epoch 92/5000\n",
      "6156/6156 [==============================] - 1s 110us/sample - loss: 0.3360 - categorical_accuracy: 0.8601 - auc: 0.9827 - precision: 0.8652 - recall: 0.8567 - val_loss: 0.2963 - val_categorical_accuracy: 0.9098 - val_auc: 0.9831 - val_precision: 0.9166 - val_recall: 0.9055\n",
      "Epoch 93/5000\n",
      "6156/6156 [==============================] - 1s 110us/sample - loss: 0.2250 - categorical_accuracy: 0.9118 - auc: 0.9904 - precision: 0.9167 - recall: 0.9061 - val_loss: 0.3330 - val_categorical_accuracy: 0.8840 - val_auc: 0.9794 - val_precision: 0.8900 - val_recall: 0.8796\n",
      "Epoch 94/5000\n",
      "6156/6156 [==============================] - 1s 113us/sample - loss: 0.1902 - categorical_accuracy: 0.9269 - auc: 0.9934 - precision: 0.9324 - recall: 0.9230 - val_loss: 0.2775 - val_categorical_accuracy: 0.9191 - val_auc: 0.9846 - val_precision: 0.9266 - val_recall: 0.9162\n",
      "Epoch 95/5000\n",
      "6156/6156 [==============================] - 1s 111us/sample - loss: 0.1735 - categorical_accuracy: 0.9384 - auc: 0.9941 - precision: 0.9426 - recall: 0.9344 - val_loss: 0.3102 - val_categorical_accuracy: 0.9035 - val_auc: 0.9818 - val_precision: 0.9086 - val_recall: 0.9006\n",
      "Epoch 96/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.1721 - categorical_accuracy: 0.9383 - auc: 0.9946 - precision: 0.9439 - recall: 0.9352 - val_loss: 0.2844 - val_categorical_accuracy: 0.9157 - val_auc: 0.9839 - val_precision: 0.9193 - val_recall: 0.9103\n",
      "Epoch 97/5000\n",
      "6156/6156 [==============================] - 1s 113us/sample - loss: 0.1699 - categorical_accuracy: 0.9417 - auc: 0.9943 - precision: 0.9471 - recall: 0.9388 - val_loss: 0.3221 - val_categorical_accuracy: 0.9011 - val_auc: 0.9809 - val_precision: 0.9044 - val_recall: 0.8991\n",
      "Epoch 98/5000\n",
      "6156/6156 [==============================] - 1s 113us/sample - loss: 0.1699 - categorical_accuracy: 0.9435 - auc: 0.9944 - precision: 0.9472 - recall: 0.9392 - val_loss: 0.2953 - val_categorical_accuracy: 0.9094 - val_auc: 0.9831 - val_precision: 0.9178 - val_recall: 0.9035\n",
      "Epoch 99/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.1720 - categorical_accuracy: 0.9420 - auc: 0.9937 - precision: 0.9452 - recall: 0.9378 - val_loss: 0.3347 - val_categorical_accuracy: 0.8981 - val_auc: 0.9807 - val_precision: 0.9005 - val_recall: 0.8957\n",
      "Epoch 100/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.1777 - categorical_accuracy: 0.9381 - auc: 0.9940 - precision: 0.9423 - recall: 0.9337 - val_loss: 0.2964 - val_categorical_accuracy: 0.9128 - val_auc: 0.9830 - val_precision: 0.9176 - val_recall: 0.9059\n",
      "Epoch 101/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.1714 - categorical_accuracy: 0.9353 - auc: 0.9941 - precision: 0.9409 - recall: 0.9306 - val_loss: 0.3786 - val_categorical_accuracy: 0.8694 - val_auc: 0.9776 - val_precision: 0.8733 - val_recall: 0.8665\n",
      "Epoch 102/5000\n",
      "6156/6156 [==============================] - 1s 115us/sample - loss: 0.2020 - categorical_accuracy: 0.9209 - auc: 0.9924 - precision: 0.9227 - recall: 0.9175 - val_loss: 0.3434 - val_categorical_accuracy: 0.8752 - val_auc: 0.9801 - val_precision: 0.8790 - val_recall: 0.8709\n",
      "Epoch 103/5000\n",
      "6156/6156 [==============================] - 1s 113us/sample - loss: 0.2570 - categorical_accuracy: 0.8884 - auc: 0.9887 - precision: 0.8912 - recall: 0.8850 - val_loss: 0.5339 - val_categorical_accuracy: 0.8124 - val_auc: 0.9660 - val_precision: 0.8186 - val_recall: 0.8070\n",
      "Epoch 104/5000\n",
      "6156/6156 [==============================] - 1s 111us/sample - loss: 0.3362 - categorical_accuracy: 0.8645 - auc: 0.9828 - precision: 0.8680 - recall: 0.8609 - val_loss: 0.2982 - val_categorical_accuracy: 0.9064 - val_auc: 0.9837 - val_precision: 0.9111 - val_recall: 0.9035\n",
      "Epoch 105/5000\n",
      "6156/6156 [==============================] - 1s 115us/sample - loss: 0.2169 - categorical_accuracy: 0.9115 - auc: 0.9910 - precision: 0.9144 - recall: 0.9074 - val_loss: 0.3372 - val_categorical_accuracy: 0.8830 - val_auc: 0.9797 - val_precision: 0.8866 - val_recall: 0.8801\n",
      "Epoch 106/5000\n",
      "6156/6156 [==============================] - 1s 111us/sample - loss: 0.1810 - categorical_accuracy: 0.9319 - auc: 0.9938 - precision: 0.9384 - recall: 0.9280 - val_loss: 0.2817 - val_categorical_accuracy: 0.9215 - val_auc: 0.9836 - val_precision: 0.9260 - val_recall: 0.9211\n",
      "Epoch 107/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.1640 - categorical_accuracy: 0.9423 - auc: 0.9949 - precision: 0.9468 - recall: 0.9394 - val_loss: 0.3162 - val_categorical_accuracy: 0.8981 - val_auc: 0.9810 - val_precision: 0.9036 - val_recall: 0.8952\n",
      "Epoch 108/5000\n",
      "6156/6156 [==============================] - 1s 111us/sample - loss: 0.1657 - categorical_accuracy: 0.9431 - auc: 0.9945 - precision: 0.9455 - recall: 0.9384 - val_loss: 0.2825 - val_categorical_accuracy: 0.9220 - val_auc: 0.9833 - val_precision: 0.9272 - val_recall: 0.9186\n",
      "Epoch 109/5000\n",
      "6156/6156 [==============================] - 1s 113us/sample - loss: 0.1625 - categorical_accuracy: 0.9436 - auc: 0.9949 - precision: 0.9496 - recall: 0.9405 - val_loss: 0.3310 - val_categorical_accuracy: 0.8894 - val_auc: 0.9803 - val_precision: 0.8939 - val_recall: 0.8865\n",
      "Epoch 110/5000\n",
      "6156/6156 [==============================] - 1s 111us/sample - loss: 0.1656 - categorical_accuracy: 0.9405 - auc: 0.9945 - precision: 0.9448 - recall: 0.9371 - val_loss: 0.2865 - val_categorical_accuracy: 0.9211 - val_auc: 0.9830 - val_precision: 0.9232 - val_recall: 0.9196\n",
      "Epoch 111/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.1702 - categorical_accuracy: 0.9399 - auc: 0.9943 - precision: 0.9425 - recall: 0.9365 - val_loss: 0.3630 - val_categorical_accuracy: 0.8743 - val_auc: 0.9780 - val_precision: 0.8794 - val_recall: 0.8709\n",
      "Epoch 112/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.1758 - categorical_accuracy: 0.9342 - auc: 0.9940 - precision: 0.9385 - recall: 0.9298 - val_loss: 0.2921 - val_categorical_accuracy: 0.9128 - val_auc: 0.9839 - val_precision: 0.9152 - val_recall: 0.9094\n",
      "Epoch 113/5000\n",
      "6156/6156 [==============================] - 1s 113us/sample - loss: 0.1805 - categorical_accuracy: 0.9250 - auc: 0.9935 - precision: 0.9299 - recall: 0.9219 - val_loss: 0.4079 - val_categorical_accuracy: 0.8577 - val_auc: 0.9755 - val_precision: 0.8599 - val_recall: 0.8553\n",
      "Epoch 114/5000\n",
      "6156/6156 [==============================] - 1s 113us/sample - loss: 0.2114 - categorical_accuracy: 0.9110 - auc: 0.9922 - precision: 0.9146 - recall: 0.9076 - val_loss: 0.3103 - val_categorical_accuracy: 0.8942 - val_auc: 0.9822 - val_precision: 0.8986 - val_recall: 0.8894\n",
      "Epoch 115/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.2104 - categorical_accuracy: 0.9087 - auc: 0.9919 - precision: 0.9137 - recall: 0.9063 - val_loss: 0.4565 - val_categorical_accuracy: 0.8324 - val_auc: 0.9708 - val_precision: 0.8347 - val_recall: 0.8270\n",
      "Epoch 116/5000\n",
      "6156/6156 [==============================] - 1s 111us/sample - loss: 0.2494 - categorical_accuracy: 0.8973 - auc: 0.9894 - precision: 0.9010 - recall: 0.8944 - val_loss: 0.2912 - val_categorical_accuracy: 0.9118 - val_auc: 0.9834 - val_precision: 0.9188 - val_recall: 0.9094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/5000\n",
      "6156/6156 [==============================] - 1s 113us/sample - loss: 0.1887 - categorical_accuracy: 0.9277 - auc: 0.9929 - precision: 0.9315 - recall: 0.9254 - val_loss: 0.3243 - val_categorical_accuracy: 0.8923 - val_auc: 0.9806 - val_precision: 0.8951 - val_recall: 0.8899\n",
      "Epoch 118/5000\n",
      "6156/6156 [==============================] - 1s 111us/sample - loss: 0.1595 - categorical_accuracy: 0.9383 - auc: 0.9952 - precision: 0.9420 - recall: 0.9347 - val_loss: 0.2789 - val_categorical_accuracy: 0.9206 - val_auc: 0.9841 - val_precision: 0.9266 - val_recall: 0.9167\n",
      "Epoch 119/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.1482 - categorical_accuracy: 0.9449 - auc: 0.9958 - precision: 0.9485 - recall: 0.9423 - val_loss: 0.3064 - val_categorical_accuracy: 0.9050 - val_auc: 0.9826 - val_precision: 0.9079 - val_recall: 0.9035\n",
      "Epoch 120/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.1443 - categorical_accuracy: 0.9503 - auc: 0.9955 - precision: 0.9531 - recall: 0.9474 - val_loss: 0.2920 - val_categorical_accuracy: 0.9176 - val_auc: 0.9838 - val_precision: 0.9218 - val_recall: 0.9133\n",
      "Epoch 121/5000\n",
      "6156/6156 [==============================] - 1s 111us/sample - loss: 0.1479 - categorical_accuracy: 0.9448 - auc: 0.9959 - precision: 0.9483 - recall: 0.9412 - val_loss: 0.3551 - val_categorical_accuracy: 0.8845 - val_auc: 0.9788 - val_precision: 0.8903 - val_recall: 0.8816\n",
      "Epoch 122/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.1831 - categorical_accuracy: 0.9358 - auc: 0.9928 - precision: 0.9393 - recall: 0.9334 - val_loss: 0.3535 - val_categorical_accuracy: 0.9055 - val_auc: 0.9777 - val_precision: 0.9088 - val_recall: 0.9030\n",
      "Epoch 123/5000\n",
      "6156/6156 [==============================] - 1s 113us/sample - loss: 0.2143 - categorical_accuracy: 0.9209 - auc: 0.9906 - precision: 0.9249 - recall: 0.9188 - val_loss: 0.4207 - val_categorical_accuracy: 0.8562 - val_auc: 0.9739 - val_precision: 0.8641 - val_recall: 0.8519\n",
      "Epoch 124/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.2221 - categorical_accuracy: 0.9159 - auc: 0.9903 - precision: 0.9201 - recall: 0.9110 - val_loss: 0.3028 - val_categorical_accuracy: 0.9142 - val_auc: 0.9834 - val_precision: 0.9190 - val_recall: 0.9123\n",
      "Epoch 125/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.1765 - categorical_accuracy: 0.9292 - auc: 0.9942 - precision: 0.9324 - recall: 0.9271 - val_loss: 0.4075 - val_categorical_accuracy: 0.8616 - val_auc: 0.9744 - val_precision: 0.8640 - val_recall: 0.8606\n",
      "Epoch 126/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.1896 - categorical_accuracy: 0.9222 - auc: 0.9934 - precision: 0.9260 - recall: 0.9185 - val_loss: 0.2892 - val_categorical_accuracy: 0.9152 - val_auc: 0.9836 - val_precision: 0.9184 - val_recall: 0.9103\n",
      "Epoch 127/5000\n",
      "6156/6156 [==============================] - 1s 113us/sample - loss: 0.1770 - categorical_accuracy: 0.9282 - auc: 0.9936 - precision: 0.9311 - recall: 0.9258 - val_loss: 0.3854 - val_categorical_accuracy: 0.8679 - val_auc: 0.9766 - val_precision: 0.8691 - val_recall: 0.8674\n",
      "Epoch 128/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.1841 - categorical_accuracy: 0.9258 - auc: 0.9936 - precision: 0.9285 - recall: 0.9225 - val_loss: 0.2836 - val_categorical_accuracy: 0.9191 - val_auc: 0.9838 - val_precision: 0.9228 - val_recall: 0.9142\n",
      "Epoch 129/5000\n",
      "6156/6156 [==============================] - 1s 115us/sample - loss: 0.1522 - categorical_accuracy: 0.9410 - auc: 0.9954 - precision: 0.9452 - recall: 0.9381 - val_loss: 0.3346 - val_categorical_accuracy: 0.8904 - val_auc: 0.9797 - val_precision: 0.8946 - val_recall: 0.8889\n",
      "Epoch 130/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.1490 - categorical_accuracy: 0.9428 - auc: 0.9958 - precision: 0.9461 - recall: 0.9389 - val_loss: 0.2855 - val_categorical_accuracy: 0.9206 - val_auc: 0.9834 - val_precision: 0.9243 - val_recall: 0.9167\n",
      "Epoch 131/5000\n",
      "6156/6156 [==============================] - 1s 114us/sample - loss: 0.1416 - categorical_accuracy: 0.9493 - auc: 0.9960 - precision: 0.9524 - recall: 0.9457 - val_loss: 0.3314 - val_categorical_accuracy: 0.8928 - val_auc: 0.9801 - val_precision: 0.8962 - val_recall: 0.8923\n",
      "Epoch 132/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.1436 - categorical_accuracy: 0.9480 - auc: 0.9959 - precision: 0.9515 - recall: 0.9456 - val_loss: 0.2881 - val_categorical_accuracy: 0.9186 - val_auc: 0.9834 - val_precision: 0.9216 - val_recall: 0.9162\n",
      "Epoch 133/5000\n",
      "6156/6156 [==============================] - 1s 118us/sample - loss: 0.1442 - categorical_accuracy: 0.9462 - auc: 0.9958 - precision: 0.9496 - recall: 0.9431 - val_loss: 0.3578 - val_categorical_accuracy: 0.8796 - val_auc: 0.9788 - val_precision: 0.8825 - val_recall: 0.8787\n",
      "Epoch 134/5000\n",
      "6156/6156 [==============================] - 1s 116us/sample - loss: 0.1582 - categorical_accuracy: 0.9388 - auc: 0.9951 - precision: 0.9417 - recall: 0.9362 - val_loss: 0.2862 - val_categorical_accuracy: 0.9142 - val_auc: 0.9844 - val_precision: 0.9198 - val_recall: 0.9113\n",
      "Epoch 135/5000\n",
      "6156/6156 [==============================] - 1s 120us/sample - loss: 0.1628 - categorical_accuracy: 0.9311 - auc: 0.9947 - precision: 0.9345 - recall: 0.9288 - val_loss: 0.4102 - val_categorical_accuracy: 0.8631 - val_auc: 0.9755 - val_precision: 0.8655 - val_recall: 0.8592\n",
      "Epoch 136/5000\n",
      "6156/6156 [==============================] - 1s 120us/sample - loss: 0.1894 - categorical_accuracy: 0.9217 - auc: 0.9935 - precision: 0.9247 - recall: 0.9191 - val_loss: 0.2911 - val_categorical_accuracy: 0.9089 - val_auc: 0.9839 - val_precision: 0.9136 - val_recall: 0.9064\n",
      "Epoch 137/5000\n",
      "6156/6156 [==============================] - 1s 119us/sample - loss: 0.1775 - categorical_accuracy: 0.9271 - auc: 0.9938 - precision: 0.9288 - recall: 0.9241 - val_loss: 0.4067 - val_categorical_accuracy: 0.8596 - val_auc: 0.9735 - val_precision: 0.8631 - val_recall: 0.8572\n",
      "Epoch 138/5000\n",
      "6156/6156 [==============================] - 1s 111us/sample - loss: 0.1862 - categorical_accuracy: 0.9241 - auc: 0.9934 - precision: 0.9277 - recall: 0.9207 - val_loss: 0.2867 - val_categorical_accuracy: 0.9196 - val_auc: 0.9834 - val_precision: 0.9226 - val_recall: 0.9181\n",
      "Epoch 139/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.1559 - categorical_accuracy: 0.9402 - auc: 0.9951 - precision: 0.9427 - recall: 0.9378 - val_loss: 0.3522 - val_categorical_accuracy: 0.8908 - val_auc: 0.9780 - val_precision: 0.8953 - val_recall: 0.8874\n",
      "Epoch 140/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.1569 - categorical_accuracy: 0.9417 - auc: 0.9950 - precision: 0.9467 - recall: 0.9379 - val_loss: 0.2910 - val_categorical_accuracy: 0.9225 - val_auc: 0.9825 - val_precision: 0.9250 - val_recall: 0.9201\n",
      "Epoch 141/5000\n",
      "6156/6156 [==============================] - 1s 113us/sample - loss: 0.1399 - categorical_accuracy: 0.9495 - auc: 0.9960 - precision: 0.9535 - recall: 0.9470 - val_loss: 0.3233 - val_categorical_accuracy: 0.9050 - val_auc: 0.9808 - val_precision: 0.9065 - val_recall: 0.9025\n",
      "Epoch 142/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.1368 - categorical_accuracy: 0.9527 - auc: 0.9959 - precision: 0.9557 - recall: 0.9498 - val_loss: 0.2829 - val_categorical_accuracy: 0.9240 - val_auc: 0.9829 - val_precision: 0.9269 - val_recall: 0.9211\n",
      "Epoch 143/5000\n",
      "6156/6156 [==============================] - 1s 111us/sample - loss: 0.1187 - categorical_accuracy: 0.9579 - auc: 0.9970 - precision: 0.9610 - recall: 0.9558 - val_loss: 0.2923 - val_categorical_accuracy: 0.9186 - val_auc: 0.9830 - val_precision: 0.9221 - val_recall: 0.9167\n",
      "Epoch 144/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.1149 - categorical_accuracy: 0.9613 - auc: 0.9972 - precision: 0.9650 - recall: 0.9592 - val_loss: 0.2867 - val_categorical_accuracy: 0.9211 - val_auc: 0.9826 - val_precision: 0.9245 - val_recall: 0.9186\n",
      "Epoch 145/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.1158 - categorical_accuracy: 0.9604 - auc: 0.9976 - precision: 0.9631 - recall: 0.9583 - val_loss: 0.2983 - val_categorical_accuracy: 0.9215 - val_auc: 0.9821 - val_precision: 0.9241 - val_recall: 0.9191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.1166 - categorical_accuracy: 0.9599 - auc: 0.9970 - precision: 0.9623 - recall: 0.9574 - val_loss: 0.2996 - val_categorical_accuracy: 0.9162 - val_auc: 0.9823 - val_precision: 0.9181 - val_recall: 0.9128\n",
      "Epoch 147/5000\n",
      "6156/6156 [==============================] - 1s 113us/sample - loss: 0.1190 - categorical_accuracy: 0.9576 - auc: 0.9971 - precision: 0.9608 - recall: 0.9548 - val_loss: 0.2945 - val_categorical_accuracy: 0.9186 - val_auc: 0.9829 - val_precision: 0.9214 - val_recall: 0.9137\n",
      "Epoch 148/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.1232 - categorical_accuracy: 0.9566 - auc: 0.9964 - precision: 0.9580 - recall: 0.9553 - val_loss: 0.3519 - val_categorical_accuracy: 0.8928 - val_auc: 0.9792 - val_precision: 0.8983 - val_recall: 0.8913\n",
      "Epoch 149/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.1460 - categorical_accuracy: 0.9472 - auc: 0.9957 - precision: 0.9508 - recall: 0.9440 - val_loss: 0.3128 - val_categorical_accuracy: 0.9050 - val_auc: 0.9816 - val_precision: 0.9099 - val_recall: 0.9001\n",
      "Epoch 150/5000\n",
      "6156/6156 [==============================] - 1s 111us/sample - loss: 0.1589 - categorical_accuracy: 0.9423 - auc: 0.9946 - precision: 0.9443 - recall: 0.9396 - val_loss: 0.5221 - val_categorical_accuracy: 0.8314 - val_auc: 0.9687 - val_precision: 0.8366 - val_recall: 0.8285\n",
      "Epoch 151/5000\n",
      "6156/6156 [==============================] - 1s 110us/sample - loss: 0.2639 - categorical_accuracy: 0.8996 - auc: 0.9889 - precision: 0.9029 - recall: 0.8973 - val_loss: 0.4072 - val_categorical_accuracy: 0.8601 - val_auc: 0.9749 - val_precision: 0.8654 - val_recall: 0.8587\n",
      "Epoch 152/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.3308 - categorical_accuracy: 0.8767 - auc: 0.9833 - precision: 0.8793 - recall: 0.8731 - val_loss: 0.5189 - val_categorical_accuracy: 0.8260 - val_auc: 0.9654 - val_precision: 0.8291 - val_recall: 0.8250\n",
      "Epoch 153/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.2791 - categorical_accuracy: 0.8800 - auc: 0.9869 - precision: 0.8850 - recall: 0.8775 - val_loss: 0.2685 - val_categorical_accuracy: 0.9235 - val_auc: 0.9856 - val_precision: 0.9278 - val_recall: 0.9211\n",
      "Epoch 154/5000\n",
      "6156/6156 [==============================] - 1s 110us/sample - loss: 0.1436 - categorical_accuracy: 0.9474 - auc: 0.9959 - precision: 0.9513 - recall: 0.9457 - val_loss: 0.2860 - val_categorical_accuracy: 0.9152 - val_auc: 0.9833 - val_precision: 0.9199 - val_recall: 0.9123\n",
      "Epoch 155/5000\n",
      "6156/6156 [==============================] - 1s 115us/sample - loss: 0.1148 - categorical_accuracy: 0.9649 - auc: 0.9972 - precision: 0.9672 - recall: 0.9633 - val_loss: 0.2774 - val_categorical_accuracy: 0.9220 - val_auc: 0.9839 - val_precision: 0.9276 - val_recall: 0.9181\n",
      "Epoch 156/5000\n",
      "6156/6156 [==============================] - 1s 110us/sample - loss: 0.1116 - categorical_accuracy: 0.9636 - auc: 0.9976 - precision: 0.9661 - recall: 0.9618 - val_loss: 0.2747 - val_categorical_accuracy: 0.9259 - val_auc: 0.9844 - val_precision: 0.9307 - val_recall: 0.9230\n",
      "Epoch 157/5000\n",
      "6156/6156 [==============================] - 1s 113us/sample - loss: 0.1064 - categorical_accuracy: 0.9664 - auc: 0.9977 - precision: 0.9685 - recall: 0.9646 - val_loss: 0.2876 - val_categorical_accuracy: 0.9191 - val_auc: 0.9831 - val_precision: 0.9257 - val_recall: 0.9172\n",
      "Epoch 158/5000\n",
      "6156/6156 [==============================] - 1s 111us/sample - loss: 0.1025 - categorical_accuracy: 0.9688 - auc: 0.9981 - precision: 0.9724 - recall: 0.9660 - val_loss: 0.2742 - val_categorical_accuracy: 0.9279 - val_auc: 0.9844 - val_precision: 0.9323 - val_recall: 0.9254\n",
      "Epoch 159/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.1055 - categorical_accuracy: 0.9654 - auc: 0.9973 - precision: 0.9680 - recall: 0.9639 - val_loss: 0.2961 - val_categorical_accuracy: 0.9186 - val_auc: 0.9828 - val_precision: 0.9222 - val_recall: 0.9181\n",
      "Epoch 160/5000\n",
      "6156/6156 [==============================] - 1s 111us/sample - loss: 0.1021 - categorical_accuracy: 0.9683 - auc: 0.9979 - precision: 0.9709 - recall: 0.9657 - val_loss: 0.2824 - val_categorical_accuracy: 0.9245 - val_auc: 0.9841 - val_precision: 0.9289 - val_recall: 0.9230\n",
      "Epoch 161/5000\n",
      "6156/6156 [==============================] - 1s 111us/sample - loss: 0.1034 - categorical_accuracy: 0.9682 - auc: 0.9974 - precision: 0.9700 - recall: 0.9665 - val_loss: 0.3119 - val_categorical_accuracy: 0.9181 - val_auc: 0.9819 - val_precision: 0.9219 - val_recall: 0.9147\n",
      "Epoch 162/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.1071 - categorical_accuracy: 0.9623 - auc: 0.9979 - precision: 0.9670 - recall: 0.9600 - val_loss: 0.2938 - val_categorical_accuracy: 0.9167 - val_auc: 0.9840 - val_precision: 0.9211 - val_recall: 0.9157\n",
      "Epoch 163/5000\n",
      "6156/6156 [==============================] - 1s 113us/sample - loss: 0.1174 - categorical_accuracy: 0.9633 - auc: 0.9963 - precision: 0.9648 - recall: 0.9618 - val_loss: 0.3222 - val_categorical_accuracy: 0.9147 - val_auc: 0.9811 - val_precision: 0.9199 - val_recall: 0.9128\n",
      "Epoch 164/5000\n",
      "6156/6156 [==============================] - 1s 111us/sample - loss: 0.1151 - categorical_accuracy: 0.9594 - auc: 0.9973 - precision: 0.9615 - recall: 0.9570 - val_loss: 0.3425 - val_categorical_accuracy: 0.8933 - val_auc: 0.9812 - val_precision: 0.8973 - val_recall: 0.8904\n",
      "Epoch 165/5000\n",
      "6156/6156 [==============================] - 1s 113us/sample - loss: 0.1347 - categorical_accuracy: 0.9513 - auc: 0.9962 - precision: 0.9532 - recall: 0.9495 - val_loss: 0.3270 - val_categorical_accuracy: 0.9069 - val_auc: 0.9804 - val_precision: 0.9093 - val_recall: 0.9040\n",
      "Epoch 166/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.1447 - categorical_accuracy: 0.9399 - auc: 0.9959 - precision: 0.9426 - recall: 0.9384 - val_loss: 0.4727 - val_categorical_accuracy: 0.8582 - val_auc: 0.9738 - val_precision: 0.8616 - val_recall: 0.8553\n",
      "Epoch 167/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.2170 - categorical_accuracy: 0.9157 - auc: 0.9923 - precision: 0.9175 - recall: 0.9147 - val_loss: 0.3012 - val_categorical_accuracy: 0.9098 - val_auc: 0.9832 - val_precision: 0.9132 - val_recall: 0.9074\n",
      "Epoch 168/5000\n",
      "6156/6156 [==============================] - 1s 113us/sample - loss: 0.1952 - categorical_accuracy: 0.9232 - auc: 0.9926 - precision: 0.9258 - recall: 0.9220 - val_loss: 0.4482 - val_categorical_accuracy: 0.8621 - val_auc: 0.9713 - val_precision: 0.8643 - val_recall: 0.8596\n",
      "Epoch 169/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.1960 - categorical_accuracy: 0.9176 - auc: 0.9931 - precision: 0.9204 - recall: 0.9160 - val_loss: 0.2837 - val_categorical_accuracy: 0.9206 - val_auc: 0.9849 - val_precision: 0.9264 - val_recall: 0.9196\n",
      "Epoch 170/5000\n",
      "6156/6156 [==============================] - 1s 111us/sample - loss: 0.1467 - categorical_accuracy: 0.9443 - auc: 0.9953 - precision: 0.9468 - recall: 0.9427 - val_loss: 0.3424 - val_categorical_accuracy: 0.8933 - val_auc: 0.9795 - val_precision: 0.8975 - val_recall: 0.8923\n",
      "Epoch 171/5000\n",
      "6156/6156 [==============================] - 1s 113us/sample - loss: 0.1186 - categorical_accuracy: 0.9539 - auc: 0.9973 - precision: 0.9567 - recall: 0.9518 - val_loss: 0.2816 - val_categorical_accuracy: 0.9288 - val_auc: 0.9837 - val_precision: 0.9333 - val_recall: 0.9274\n",
      "Epoch 172/5000\n",
      "6156/6156 [==============================] - 1s 113us/sample - loss: 0.1010 - categorical_accuracy: 0.9672 - auc: 0.9977 - precision: 0.9692 - recall: 0.9656 - val_loss: 0.3015 - val_categorical_accuracy: 0.9137 - val_auc: 0.9820 - val_precision: 0.9175 - val_recall: 0.9108\n",
      "Epoch 173/5000\n",
      "6156/6156 [==============================] - 1s 111us/sample - loss: 0.0984 - categorical_accuracy: 0.9691 - auc: 0.9980 - precision: 0.9706 - recall: 0.9667 - val_loss: 0.2863 - val_categorical_accuracy: 0.9279 - val_auc: 0.9837 - val_precision: 0.9305 - val_recall: 0.9264\n",
      "Epoch 174/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.0950 - categorical_accuracy: 0.9704 - auc: 0.9979 - precision: 0.9729 - recall: 0.9688 - val_loss: 0.3053 - val_categorical_accuracy: 0.9152 - val_auc: 0.9819 - val_precision: 0.9178 - val_recall: 0.9137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/5000\n",
      "6156/6156 [==============================] - 1s 111us/sample - loss: 0.0929 - categorical_accuracy: 0.9704 - auc: 0.9980 - precision: 0.9729 - recall: 0.9690 - val_loss: 0.2808 - val_categorical_accuracy: 0.9279 - val_auc: 0.9840 - val_precision: 0.9305 - val_recall: 0.9259\n",
      "Epoch 176/5000\n",
      "6156/6156 [==============================] - 1s 111us/sample - loss: 0.0923 - categorical_accuracy: 0.9698 - auc: 0.9981 - precision: 0.9710 - recall: 0.9675 - val_loss: 0.3331 - val_categorical_accuracy: 0.9025 - val_auc: 0.9803 - val_precision: 0.9067 - val_recall: 0.9001\n",
      "Epoch 177/5000\n",
      "6156/6156 [==============================] - 1s 114us/sample - loss: 0.0992 - categorical_accuracy: 0.9643 - auc: 0.9978 - precision: 0.9667 - recall: 0.9625 - val_loss: 0.2901 - val_categorical_accuracy: 0.9240 - val_auc: 0.9834 - val_precision: 0.9275 - val_recall: 0.9220\n",
      "Epoch 178/5000\n",
      "6156/6156 [==============================] - 1s 111us/sample - loss: 0.1122 - categorical_accuracy: 0.9584 - auc: 0.9971 - precision: 0.9601 - recall: 0.9565 - val_loss: 0.4462 - val_categorical_accuracy: 0.8709 - val_auc: 0.9748 - val_precision: 0.8727 - val_recall: 0.8689\n",
      "Epoch 179/5000\n",
      "6156/6156 [==============================] - 1s 111us/sample - loss: 0.1702 - categorical_accuracy: 0.9329 - auc: 0.9949 - precision: 0.9351 - recall: 0.9313 - val_loss: 0.3173 - val_categorical_accuracy: 0.9069 - val_auc: 0.9814 - val_precision: 0.9103 - val_recall: 0.9050\n",
      "Epoch 180/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.1789 - categorical_accuracy: 0.9209 - auc: 0.9938 - precision: 0.9240 - recall: 0.9206 - val_loss: 0.5007 - val_categorical_accuracy: 0.8465 - val_auc: 0.9709 - val_precision: 0.8490 - val_recall: 0.8441\n",
      "Epoch 181/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.2347 - categorical_accuracy: 0.9040 - auc: 0.9911 - precision: 0.9062 - recall: 0.9020 - val_loss: 0.2946 - val_categorical_accuracy: 0.9142 - val_auc: 0.9832 - val_precision: 0.9176 - val_recall: 0.9123\n",
      "Epoch 182/5000\n",
      "6156/6156 [==============================] - 1s 119us/sample - loss: 0.1557 - categorical_accuracy: 0.9379 - auc: 0.9950 - precision: 0.9401 - recall: 0.9360 - val_loss: 0.3506 - val_categorical_accuracy: 0.8938 - val_auc: 0.9794 - val_precision: 0.8986 - val_recall: 0.8938\n",
      "Epoch 183/5000\n",
      "6156/6156 [==============================] - 1s 116us/sample - loss: 0.1267 - categorical_accuracy: 0.9539 - auc: 0.9965 - precision: 0.9561 - recall: 0.9509 - val_loss: 0.2784 - val_categorical_accuracy: 0.9274 - val_auc: 0.9841 - val_precision: 0.9313 - val_recall: 0.9254\n",
      "Epoch 184/5000\n",
      "6156/6156 [==============================] - 1s 122us/sample - loss: 0.0988 - categorical_accuracy: 0.9685 - auc: 0.9981 - precision: 0.9708 - recall: 0.9667 - val_loss: 0.2910 - val_categorical_accuracy: 0.9211 - val_auc: 0.9834 - val_precision: 0.9250 - val_recall: 0.9196\n",
      "Epoch 185/5000\n",
      "6156/6156 [==============================] - 1s 118us/sample - loss: 0.0948 - categorical_accuracy: 0.9698 - auc: 0.9978 - precision: 0.9713 - recall: 0.9693 - val_loss: 0.3022 - val_categorical_accuracy: 0.9225 - val_auc: 0.9824 - val_precision: 0.9292 - val_recall: 0.9215\n",
      "Epoch 186/5000\n",
      "6156/6156 [==============================] - 1s 121us/sample - loss: 0.1065 - categorical_accuracy: 0.9649 - auc: 0.9978 - precision: 0.9675 - recall: 0.9618 - val_loss: 0.3246 - val_categorical_accuracy: 0.9113 - val_auc: 0.9809 - val_precision: 0.9160 - val_recall: 0.9089\n",
      "Epoch 187/5000\n",
      "6156/6156 [==============================] - 1s 117us/sample - loss: 0.1300 - categorical_accuracy: 0.9620 - auc: 0.9951 - precision: 0.9635 - recall: 0.9605 - val_loss: 0.3372 - val_categorical_accuracy: 0.9211 - val_auc: 0.9798 - val_precision: 0.9241 - val_recall: 0.9201\n",
      "Epoch 188/5000\n",
      "6156/6156 [==============================] - 1s 117us/sample - loss: 0.1326 - categorical_accuracy: 0.9604 - auc: 0.9959 - precision: 0.9634 - recall: 0.9581 - val_loss: 0.3183 - val_categorical_accuracy: 0.9098 - val_auc: 0.9816 - val_precision: 0.9141 - val_recall: 0.9079\n",
      "Epoch 189/5000\n",
      "6156/6156 [==============================] - 1s 115us/sample - loss: 0.1053 - categorical_accuracy: 0.9651 - auc: 0.9972 - precision: 0.9666 - recall: 0.9639 - val_loss: 0.2942 - val_categorical_accuracy: 0.9254 - val_auc: 0.9826 - val_precision: 0.9281 - val_recall: 0.9250\n",
      "Epoch 190/5000\n",
      "6156/6156 [==============================] - 1s 113us/sample - loss: 0.0917 - categorical_accuracy: 0.9683 - auc: 0.9983 - precision: 0.9705 - recall: 0.9664 - val_loss: 0.3433 - val_categorical_accuracy: 0.9016 - val_auc: 0.9806 - val_precision: 0.9053 - val_recall: 0.8996\n",
      "Epoch 191/5000\n",
      "6156/6156 [==============================] - 1s 111us/sample - loss: 0.1026 - categorical_accuracy: 0.9628 - auc: 0.9977 - precision: 0.9646 - recall: 0.9609 - val_loss: 0.2992 - val_categorical_accuracy: 0.9225 - val_auc: 0.9826 - val_precision: 0.9255 - val_recall: 0.9206\n",
      "Epoch 192/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.1182 - categorical_accuracy: 0.9519 - auc: 0.9971 - precision: 0.9539 - recall: 0.9503 - val_loss: 0.4518 - val_categorical_accuracy: 0.8723 - val_auc: 0.9749 - val_precision: 0.8733 - val_recall: 0.8704\n",
      "Epoch 193/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.1654 - categorical_accuracy: 0.9337 - auc: 0.9953 - precision: 0.9355 - recall: 0.9310 - val_loss: 0.2992 - val_categorical_accuracy: 0.9162 - val_auc: 0.9835 - val_precision: 0.9183 - val_recall: 0.9142\n",
      "Epoch 194/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.1560 - categorical_accuracy: 0.9350 - auc: 0.9950 - precision: 0.9366 - recall: 0.9332 - val_loss: 0.4715 - val_categorical_accuracy: 0.8523 - val_auc: 0.9699 - val_precision: 0.8546 - val_recall: 0.8509\n",
      "Epoch 195/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.1816 - categorical_accuracy: 0.9245 - auc: 0.9944 - precision: 0.9265 - recall: 0.9219 - val_loss: 0.3273 - val_categorical_accuracy: 0.9162 - val_auc: 0.9801 - val_precision: 0.9191 - val_recall: 0.9137\n",
      "Epoch 196/5000\n",
      "6156/6156 [==============================] - 1s 114us/sample - loss: 0.1649 - categorical_accuracy: 0.9414 - auc: 0.9942 - precision: 0.9430 - recall: 0.9384 - val_loss: 0.5557 - val_categorical_accuracy: 0.8543 - val_auc: 0.9568 - val_precision: 0.8576 - val_recall: 0.8514\n",
      "Epoch 197/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.2383 - categorical_accuracy: 0.9274 - auc: 0.9871 - precision: 0.9330 - recall: 0.9237 - val_loss: 0.3650 - val_categorical_accuracy: 0.9001 - val_auc: 0.9762 - val_precision: 0.9051 - val_recall: 0.8972\n",
      "Epoch 198/5000\n",
      "6156/6156 [==============================] - 1s 113us/sample - loss: 0.2165 - categorical_accuracy: 0.9305 - auc: 0.9900 - precision: 0.9365 - recall: 0.9267 - val_loss: 0.3402 - val_categorical_accuracy: 0.9147 - val_auc: 0.9776 - val_precision: 0.9197 - val_recall: 0.9103\n",
      "Epoch 199/5000\n",
      "6156/6156 [==============================] - 1s 119us/sample - loss: 0.1400 - categorical_accuracy: 0.9501 - auc: 0.9956 - precision: 0.9525 - recall: 0.9485 - val_loss: 0.2951 - val_categorical_accuracy: 0.9167 - val_auc: 0.9830 - val_precision: 0.9192 - val_recall: 0.9142\n",
      "Epoch 200/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.0977 - categorical_accuracy: 0.9660 - auc: 0.9979 - precision: 0.9681 - recall: 0.9647 - val_loss: 0.2736 - val_categorical_accuracy: 0.9288 - val_auc: 0.9844 - val_precision: 0.9328 - val_recall: 0.9274\n",
      "Epoch 201/5000\n",
      "6156/6156 [==============================] - 1s 118us/sample - loss: 0.0866 - categorical_accuracy: 0.9721 - auc: 0.9984 - precision: 0.9735 - recall: 0.9712 - val_loss: 0.2884 - val_categorical_accuracy: 0.9225 - val_auc: 0.9835 - val_precision: 0.9261 - val_recall: 0.9220\n",
      "Epoch 202/5000\n",
      "6156/6156 [==============================] - 1s 118us/sample - loss: 0.0824 - categorical_accuracy: 0.9734 - auc: 0.9986 - precision: 0.9754 - recall: 0.9722 - val_loss: 0.2787 - val_categorical_accuracy: 0.9284 - val_auc: 0.9839 - val_precision: 0.9333 - val_recall: 0.9269\n",
      "Epoch 203/5000\n",
      "6156/6156 [==============================] - 1s 111us/sample - loss: 0.0816 - categorical_accuracy: 0.9738 - auc: 0.9986 - precision: 0.9756 - recall: 0.9722 - val_loss: 0.2919 - val_categorical_accuracy: 0.9230 - val_auc: 0.9834 - val_precision: 0.9279 - val_recall: 0.9225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 204/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.0795 - categorical_accuracy: 0.9730 - auc: 0.9985 - precision: 0.9752 - recall: 0.9714 - val_loss: 0.2798 - val_categorical_accuracy: 0.9284 - val_auc: 0.9838 - val_precision: 0.9338 - val_recall: 0.9279\n",
      "Epoch 205/5000\n",
      "6156/6156 [==============================] - 1s 119us/sample - loss: 0.0793 - categorical_accuracy: 0.9735 - auc: 0.9987 - precision: 0.9747 - recall: 0.9719 - val_loss: 0.3153 - val_categorical_accuracy: 0.9152 - val_auc: 0.9825 - val_precision: 0.9177 - val_recall: 0.9133\n",
      "Epoch 206/5000\n",
      "6156/6156 [==============================] - 1s 116us/sample - loss: 0.0838 - categorical_accuracy: 0.9717 - auc: 0.9985 - precision: 0.9731 - recall: 0.9693 - val_loss: 0.2891 - val_categorical_accuracy: 0.9230 - val_auc: 0.9830 - val_precision: 0.9274 - val_recall: 0.9211\n",
      "Epoch 207/5000\n",
      "6156/6156 [==============================] - 1s 111us/sample - loss: 0.0924 - categorical_accuracy: 0.9647 - auc: 0.9982 - precision: 0.9669 - recall: 0.9638 - val_loss: 0.4127 - val_categorical_accuracy: 0.8811 - val_auc: 0.9771 - val_precision: 0.8849 - val_recall: 0.8806\n",
      "Epoch 208/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.1348 - categorical_accuracy: 0.9495 - auc: 0.9968 - precision: 0.9508 - recall: 0.9477 - val_loss: 0.3250 - val_categorical_accuracy: 0.9059 - val_auc: 0.9811 - val_precision: 0.9080 - val_recall: 0.9040\n",
      "Epoch 209/5000\n",
      "6156/6156 [==============================] - 1s 113us/sample - loss: 0.1706 - categorical_accuracy: 0.9250 - auc: 0.9945 - precision: 0.9264 - recall: 0.9238 - val_loss: 0.5666 - val_categorical_accuracy: 0.8411 - val_auc: 0.9667 - val_precision: 0.8435 - val_recall: 0.8377\n",
      "Epoch 210/5000\n",
      "6156/6156 [==============================] - 1s 114us/sample - loss: 0.2604 - categorical_accuracy: 0.8996 - auc: 0.9896 - precision: 0.9012 - recall: 0.8978 - val_loss: 0.2778 - val_categorical_accuracy: 0.9240 - val_auc: 0.9844 - val_precision: 0.9257 - val_recall: 0.9235\n",
      "Epoch 211/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.1329 - categorical_accuracy: 0.9511 - auc: 0.9963 - precision: 0.9533 - recall: 0.9490 - val_loss: 0.3263 - val_categorical_accuracy: 0.9084 - val_auc: 0.9805 - val_precision: 0.9101 - val_recall: 0.9074\n",
      "Epoch 212/5000\n",
      "6156/6156 [==============================] - 1s 114us/sample - loss: 0.0986 - categorical_accuracy: 0.9657 - auc: 0.9979 - precision: 0.9690 - recall: 0.9641 - val_loss: 0.2765 - val_categorical_accuracy: 0.9332 - val_auc: 0.9843 - val_precision: 0.9349 - val_recall: 0.9308\n",
      "Epoch 213/5000\n",
      "6156/6156 [==============================] - 1s 113us/sample - loss: 0.0849 - categorical_accuracy: 0.9743 - auc: 0.9982 - precision: 0.9761 - recall: 0.9742 - val_loss: 0.2995 - val_categorical_accuracy: 0.9235 - val_auc: 0.9823 - val_precision: 0.9261 - val_recall: 0.9215\n",
      "Epoch 214/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.0794 - categorical_accuracy: 0.9761 - auc: 0.9987 - precision: 0.9780 - recall: 0.9745 - val_loss: 0.2822 - val_categorical_accuracy: 0.9323 - val_auc: 0.9839 - val_precision: 0.9348 - val_recall: 0.9293\n",
      "Epoch 215/5000\n",
      "6156/6156 [==============================] - 1s 113us/sample - loss: 0.0806 - categorical_accuracy: 0.9760 - auc: 0.9980 - precision: 0.9774 - recall: 0.9747 - val_loss: 0.3038 - val_categorical_accuracy: 0.9215 - val_auc: 0.9819 - val_precision: 0.9259 - val_recall: 0.9191\n",
      "Epoch 216/5000\n",
      "6156/6156 [==============================] - 1s 114us/sample - loss: 0.0769 - categorical_accuracy: 0.9782 - auc: 0.9987 - precision: 0.9798 - recall: 0.9761 - val_loss: 0.2873 - val_categorical_accuracy: 0.9318 - val_auc: 0.9829 - val_precision: 0.9353 - val_recall: 0.9293\n",
      "Epoch 217/5000\n",
      "6156/6156 [==============================] - 1s 120us/sample - loss: 0.0851 - categorical_accuracy: 0.9738 - auc: 0.9979 - precision: 0.9748 - recall: 0.9727 - val_loss: 0.3232 - val_categorical_accuracy: 0.9167 - val_auc: 0.9807 - val_precision: 0.9219 - val_recall: 0.9152\n",
      "Epoch 218/5000\n",
      "6156/6156 [==============================] - 1s 114us/sample - loss: 0.0852 - categorical_accuracy: 0.9717 - auc: 0.9986 - precision: 0.9742 - recall: 0.9703 - val_loss: 0.2936 - val_categorical_accuracy: 0.9269 - val_auc: 0.9825 - val_precision: 0.9322 - val_recall: 0.9250\n",
      "Epoch 219/5000\n",
      "6156/6156 [==============================] - 1s 117us/sample - loss: 0.0855 - categorical_accuracy: 0.9721 - auc: 0.9978 - precision: 0.9744 - recall: 0.9719 - val_loss: 0.3163 - val_categorical_accuracy: 0.9191 - val_auc: 0.9806 - val_precision: 0.9217 - val_recall: 0.9176\n",
      "Epoch 220/5000\n",
      "6156/6156 [==============================] - 1s 120us/sample - loss: 0.0742 - categorical_accuracy: 0.9758 - auc: 0.9990 - precision: 0.9773 - recall: 0.9738 - val_loss: 0.2856 - val_categorical_accuracy: 0.9303 - val_auc: 0.9834 - val_precision: 0.9330 - val_recall: 0.9298\n",
      "Epoch 221/5000\n",
      "6156/6156 [==============================] - 1s 121us/sample - loss: 0.0714 - categorical_accuracy: 0.9766 - auc: 0.9986 - precision: 0.9779 - recall: 0.9756 - val_loss: 0.3294 - val_categorical_accuracy: 0.9167 - val_auc: 0.9799 - val_precision: 0.9191 - val_recall: 0.9137\n",
      "Epoch 222/5000\n",
      "6156/6156 [==============================] - 1s 121us/sample - loss: 0.0748 - categorical_accuracy: 0.9738 - auc: 0.9988 - precision: 0.9773 - recall: 0.9727 - val_loss: 0.2817 - val_categorical_accuracy: 0.9303 - val_auc: 0.9840 - val_precision: 0.9330 - val_recall: 0.9293\n",
      "Epoch 223/5000\n",
      "6156/6156 [==============================] - 1s 118us/sample - loss: 0.0806 - categorical_accuracy: 0.9716 - auc: 0.9984 - precision: 0.9730 - recall: 0.9703 - val_loss: 0.3858 - val_categorical_accuracy: 0.9035 - val_auc: 0.9761 - val_precision: 0.9057 - val_recall: 0.9035\n",
      "Epoch 224/5000\n",
      "6156/6156 [==============================] - 1s 125us/sample - loss: 0.1021 - categorical_accuracy: 0.9622 - auc: 0.9979 - precision: 0.9646 - recall: 0.9605 - val_loss: 0.2914 - val_categorical_accuracy: 0.9235 - val_auc: 0.9838 - val_precision: 0.9251 - val_recall: 0.9215\n",
      "Epoch 225/5000\n",
      "6156/6156 [==============================] - 1s 113us/sample - loss: 0.1107 - categorical_accuracy: 0.9566 - auc: 0.9973 - precision: 0.9578 - recall: 0.9558 - val_loss: 0.4439 - val_categorical_accuracy: 0.8879 - val_auc: 0.9719 - val_precision: 0.8887 - val_recall: 0.8869\n",
      "Epoch 226/5000\n",
      "6156/6156 [==============================] - 1s 111us/sample - loss: 0.1371 - categorical_accuracy: 0.9461 - auc: 0.9964 - precision: 0.9486 - recall: 0.9441 - val_loss: 0.3143 - val_categorical_accuracy: 0.9162 - val_auc: 0.9830 - val_precision: 0.9183 - val_recall: 0.9147\n",
      "Epoch 227/5000\n",
      "6156/6156 [==============================] - 1s 111us/sample - loss: 0.1500 - categorical_accuracy: 0.9414 - auc: 0.9951 - precision: 0.9430 - recall: 0.9402 - val_loss: 0.5273 - val_categorical_accuracy: 0.8509 - val_auc: 0.9710 - val_precision: 0.8536 - val_recall: 0.8494\n",
      "Epoch 228/5000\n",
      "6156/6156 [==============================] - 1s 111us/sample - loss: 0.2069 - categorical_accuracy: 0.9176 - auc: 0.9936 - precision: 0.9189 - recall: 0.9163 - val_loss: 0.3446 - val_categorical_accuracy: 0.8991 - val_auc: 0.9791 - val_precision: 0.9024 - val_recall: 0.8967\n",
      "Epoch 229/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.1767 - categorical_accuracy: 0.9323 - auc: 0.9938 - precision: 0.9351 - recall: 0.9298 - val_loss: 0.4481 - val_categorical_accuracy: 0.8674 - val_auc: 0.9736 - val_precision: 0.8706 - val_recall: 0.8655\n",
      "Epoch 230/5000\n",
      "6156/6156 [==============================] - 1s 114us/sample - loss: 0.1844 - categorical_accuracy: 0.9323 - auc: 0.9933 - precision: 0.9346 - recall: 0.9306 - val_loss: 0.2960 - val_categorical_accuracy: 0.9215 - val_auc: 0.9824 - val_precision: 0.9241 - val_recall: 0.9201\n",
      "Epoch 231/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.0906 - categorical_accuracy: 0.9690 - auc: 0.9984 - precision: 0.9718 - recall: 0.9673 - val_loss: 0.2966 - val_categorical_accuracy: 0.9254 - val_auc: 0.9825 - val_precision: 0.9285 - val_recall: 0.9240\n",
      "Epoch 232/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.0817 - categorical_accuracy: 0.9758 - auc: 0.9981 - precision: 0.9771 - recall: 0.9753 - val_loss: 0.2924 - val_categorical_accuracy: 0.9274 - val_auc: 0.9823 - val_precision: 0.9308 - val_recall: 0.9240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233/5000\n",
      "6156/6156 [==============================] - 1s 111us/sample - loss: 0.0705 - categorical_accuracy: 0.9807 - auc: 0.9990 - precision: 0.9821 - recall: 0.9789 - val_loss: 0.2906 - val_categorical_accuracy: 0.9293 - val_auc: 0.9826 - val_precision: 0.9329 - val_recall: 0.9279\n",
      "Epoch 234/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.0678 - categorical_accuracy: 0.9797 - auc: 0.9987 - precision: 0.9814 - recall: 0.9784 - val_loss: 0.2967 - val_categorical_accuracy: 0.9269 - val_auc: 0.9822 - val_precision: 0.9304 - val_recall: 0.9250\n",
      "Epoch 235/5000\n",
      "6156/6156 [==============================] - 1s 114us/sample - loss: 0.0686 - categorical_accuracy: 0.9779 - auc: 0.9989 - precision: 0.9795 - recall: 0.9763 - val_loss: 0.2934 - val_categorical_accuracy: 0.9293 - val_auc: 0.9830 - val_precision: 0.9310 - val_recall: 0.9274\n",
      "Epoch 236/5000\n",
      "6156/6156 [==============================] - 1s 111us/sample - loss: 0.0660 - categorical_accuracy: 0.9789 - auc: 0.9988 - precision: 0.9797 - recall: 0.9781 - val_loss: 0.3043 - val_categorical_accuracy: 0.9274 - val_auc: 0.9817 - val_precision: 0.9304 - val_recall: 0.9245\n",
      "Epoch 237/5000\n",
      "6156/6156 [==============================] - 1s 113us/sample - loss: 0.0639 - categorical_accuracy: 0.9810 - auc: 0.9990 - precision: 0.9824 - recall: 0.9797 - val_loss: 0.2965 - val_categorical_accuracy: 0.9318 - val_auc: 0.9830 - val_precision: 0.9335 - val_recall: 0.9298\n",
      "Epoch 238/5000\n",
      "6156/6156 [==============================] - 1s 114us/sample - loss: 0.0645 - categorical_accuracy: 0.9815 - auc: 0.9986 - precision: 0.9826 - recall: 0.9802 - val_loss: 0.3114 - val_categorical_accuracy: 0.9269 - val_auc: 0.9818 - val_precision: 0.9300 - val_recall: 0.9264\n",
      "Epoch 239/5000\n",
      "6156/6156 [==============================] - 1s 113us/sample - loss: 0.0649 - categorical_accuracy: 0.9813 - auc: 0.9991 - precision: 0.9822 - recall: 0.9790 - val_loss: 0.3034 - val_categorical_accuracy: 0.9279 - val_auc: 0.9822 - val_precision: 0.9319 - val_recall: 0.9269\n",
      "Epoch 240/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.0741 - categorical_accuracy: 0.9760 - auc: 0.9981 - precision: 0.9770 - recall: 0.9750 - val_loss: 0.3371 - val_categorical_accuracy: 0.9176 - val_auc: 0.9802 - val_precision: 0.9235 - val_recall: 0.9172\n",
      "Epoch 241/5000\n",
      "6156/6156 [==============================] - 1s 113us/sample - loss: 0.0807 - categorical_accuracy: 0.9721 - auc: 0.9987 - precision: 0.9744 - recall: 0.9696 - val_loss: 0.3613 - val_categorical_accuracy: 0.9035 - val_auc: 0.9786 - val_precision: 0.9064 - val_recall: 0.9011\n",
      "Epoch 242/5000\n",
      "6156/6156 [==============================] - 1s 111us/sample - loss: 0.1099 - categorical_accuracy: 0.9657 - auc: 0.9964 - precision: 0.9668 - recall: 0.9646 - val_loss: 0.3588 - val_categorical_accuracy: 0.9157 - val_auc: 0.9795 - val_precision: 0.9187 - val_recall: 0.9147\n",
      "Epoch 243/5000\n",
      "6156/6156 [==============================] - 1s 110us/sample - loss: 0.1156 - categorical_accuracy: 0.9587 - auc: 0.9971 - precision: 0.9604 - recall: 0.9561 - val_loss: 0.4756 - val_categorical_accuracy: 0.8743 - val_auc: 0.9729 - val_precision: 0.8767 - val_recall: 0.8728\n",
      "Epoch 244/5000\n",
      "6156/6156 [==============================] - 1s 111us/sample - loss: 0.1644 - categorical_accuracy: 0.9388 - auc: 0.9950 - precision: 0.9409 - recall: 0.9379 - val_loss: 0.3265 - val_categorical_accuracy: 0.9108 - val_auc: 0.9810 - val_precision: 0.9126 - val_recall: 0.9103\n",
      "Epoch 245/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.1726 - categorical_accuracy: 0.9310 - auc: 0.9944 - precision: 0.9333 - recall: 0.9295 - val_loss: 0.5546 - val_categorical_accuracy: 0.8504 - val_auc: 0.9641 - val_precision: 0.8519 - val_recall: 0.8494\n",
      "Epoch 246/5000\n",
      "6156/6156 [==============================] - 1s 111us/sample - loss: 0.2331 - categorical_accuracy: 0.9094 - auc: 0.9918 - precision: 0.9115 - recall: 0.9072 - val_loss: 0.2911 - val_categorical_accuracy: 0.9240 - val_auc: 0.9830 - val_precision: 0.9261 - val_recall: 0.9225\n",
      "Epoch 247/5000\n",
      "6156/6156 [==============================] - 1s 111us/sample - loss: 0.1178 - categorical_accuracy: 0.9574 - auc: 0.9969 - precision: 0.9584 - recall: 0.9555 - val_loss: 0.3337 - val_categorical_accuracy: 0.9079 - val_auc: 0.9799 - val_precision: 0.9118 - val_recall: 0.9069\n",
      "Epoch 248/5000\n",
      "6156/6156 [==============================] - 1s 111us/sample - loss: 0.0796 - categorical_accuracy: 0.9738 - auc: 0.9987 - precision: 0.9756 - recall: 0.9724 - val_loss: 0.2905 - val_categorical_accuracy: 0.9279 - val_auc: 0.9834 - val_precision: 0.9319 - val_recall: 0.9269\n",
      "Epoch 249/5000\n",
      "6156/6156 [==============================] - 1s 111us/sample - loss: 0.0650 - categorical_accuracy: 0.9810 - auc: 0.9989 - precision: 0.9824 - recall: 0.9799 - val_loss: 0.2976 - val_categorical_accuracy: 0.9250 - val_auc: 0.9829 - val_precision: 0.9285 - val_recall: 0.9240\n",
      "Epoch 250/5000\n",
      "6156/6156 [==============================] - 1s 111us/sample - loss: 0.0641 - categorical_accuracy: 0.9808 - auc: 0.9991 - precision: 0.9821 - recall: 0.9799 - val_loss: 0.2953 - val_categorical_accuracy: 0.9288 - val_auc: 0.9829 - val_precision: 0.9307 - val_recall: 0.9288\n",
      "Epoch 251/5000\n",
      "6156/6156 [==============================] - 1s 111us/sample - loss: 0.0614 - categorical_accuracy: 0.9810 - auc: 0.9991 - precision: 0.9831 - recall: 0.9803 - val_loss: 0.3017 - val_categorical_accuracy: 0.9279 - val_auc: 0.9826 - val_precision: 0.9300 - val_recall: 0.9264\n",
      "Epoch 252/5000\n",
      "6156/6156 [==============================] - 1s 115us/sample - loss: 0.0588 - categorical_accuracy: 0.9820 - auc: 0.9992 - precision: 0.9829 - recall: 0.9805 - val_loss: 0.3001 - val_categorical_accuracy: 0.9279 - val_auc: 0.9830 - val_precision: 0.9305 - val_recall: 0.9269\n",
      "Epoch 253/5000\n",
      "6156/6156 [==============================] - 1s 116us/sample - loss: 0.0591 - categorical_accuracy: 0.9828 - auc: 0.9991 - precision: 0.9836 - recall: 0.9825 - val_loss: 0.3100 - val_categorical_accuracy: 0.9245 - val_auc: 0.9818 - val_precision: 0.9280 - val_recall: 0.9235\n",
      "Epoch 254/5000\n",
      "6156/6156 [==============================] - 1s 118us/sample - loss: 0.0585 - categorical_accuracy: 0.9816 - auc: 0.9992 - precision: 0.9835 - recall: 0.9805 - val_loss: 0.3026 - val_categorical_accuracy: 0.9303 - val_auc: 0.9829 - val_precision: 0.9338 - val_recall: 0.9284\n",
      "Epoch 255/5000\n",
      "6156/6156 [==============================] - 1s 116us/sample - loss: 0.0584 - categorical_accuracy: 0.9816 - auc: 0.9990 - precision: 0.9819 - recall: 0.9805 - val_loss: 0.3174 - val_categorical_accuracy: 0.9250 - val_auc: 0.9812 - val_precision: 0.9276 - val_recall: 0.9240\n",
      "Epoch 256/5000\n",
      "6156/6156 [==============================] - 1s 116us/sample - loss: 0.0565 - categorical_accuracy: 0.9834 - auc: 0.9992 - precision: 0.9849 - recall: 0.9821 - val_loss: 0.3161 - val_categorical_accuracy: 0.9269 - val_auc: 0.9817 - val_precision: 0.9295 - val_recall: 0.9254\n",
      "Epoch 257/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.0662 - categorical_accuracy: 0.9795 - auc: 0.9988 - precision: 0.9806 - recall: 0.9784 - val_loss: 0.3851 - val_categorical_accuracy: 0.9079 - val_auc: 0.9760 - val_precision: 0.9114 - val_recall: 0.9069\n",
      "Epoch 258/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.1042 - categorical_accuracy: 0.9667 - auc: 0.9970 - precision: 0.9670 - recall: 0.9656 - val_loss: 0.4959 - val_categorical_accuracy: 0.8830 - val_auc: 0.9683 - val_precision: 0.8885 - val_recall: 0.8811\n",
      "Epoch 259/5000\n",
      "6156/6156 [==============================] - 1s 116us/sample - loss: 0.3463 - categorical_accuracy: 0.9072 - auc: 0.9797 - precision: 0.9129 - recall: 0.9040 - val_loss: 0.7419 - val_categorical_accuracy: 0.8270 - val_auc: 0.9405 - val_precision: 0.8301 - val_recall: 0.8236\n",
      "Epoch 260/5000\n",
      "6156/6156 [==============================] - 1s 112us/sample - loss: 0.3636 - categorical_accuracy: 0.8910 - auc: 0.9760 - precision: 0.8959 - recall: 0.8865 - val_loss: 0.3169 - val_categorical_accuracy: 0.9147 - val_auc: 0.9816 - val_precision: 0.9172 - val_recall: 0.9128\n",
      "Epoch 261/5000\n",
      "6156/6156 [==============================] - 1s 114us/sample - loss: 0.1234 - categorical_accuracy: 0.9581 - auc: 0.9965 - precision: 0.9603 - recall: 0.9560 - val_loss: 0.2885 - val_categorical_accuracy: 0.9254 - val_auc: 0.9836 - val_precision: 0.9271 - val_recall: 0.9240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 262/5000\n",
      "6156/6156 [==============================] - 1s 114us/sample - loss: 0.0742 - categorical_accuracy: 0.9751 - auc: 0.9990 - precision: 0.9768 - recall: 0.9721 - val_loss: 0.3084 - val_categorical_accuracy: 0.9196 - val_auc: 0.9832 - val_precision: 0.9212 - val_recall: 0.9172\n",
      "Epoch 263/5000\n",
      "6156/6156 [==============================] - 1s 116us/sample - loss: 0.0700 - categorical_accuracy: 0.9771 - auc: 0.9988 - precision: 0.9779 - recall: 0.9763 - val_loss: 0.2874 - val_categorical_accuracy: 0.9274 - val_auc: 0.9837 - val_precision: 0.9295 - val_recall: 0.9254\n",
      "Epoch 264/5000\n",
      "6156/6156 [==============================] - 1s 94us/sample\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-de0dd665acc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# Parallelize job across 2 workers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m );\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Model training\n",
    "model.fit(\n",
    "    \n",
    "    # Input dataset\n",
    "    x=X, # windowed observations\n",
    "    y=Y, # 1-hot motion class labels\n",
    "    \n",
    "    # Batch size\n",
    "    batch_size=N_batch,\n",
    "    \n",
    "    # Number of training epochs\n",
    "    epochs=N_epoch,\n",
    "    \n",
    "    # Print progress\n",
    "    verbose=1,\n",
    "    \n",
    "    # Set aside fraction for validation\n",
    "    validation_split=pct_validation,\n",
    "    \n",
    "    # False for time series\n",
    "    shuffle=False,\n",
    "    \n",
    "    # Other misc params\n",
    "    sample_weight=None,\n",
    "    validation_freq=1,\n",
    "    max_queue_size=10,\n",
    "    \n",
    "    # Parallelize job across 2 workers\n",
    "    workers=2,\n",
    "    use_multiprocessing=True\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\textbf{Metrics vs. Training Epoch}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "# Text legend labels for training set curves\n",
    "train_set_lbl = ('Training Set (' + \n",
    "    str(int(100 * (1 - pct_validation))) + '%)');\n",
    "    \n",
    "# Text legend labels for validation set curves\n",
    "val_set_lbl = ('Training Set (' + \n",
    "    str(int(100 * (1 - pct_validation))) + '%)');\n",
    "\n",
    "# New figure\n",
    "loss_fig = plt.figure(figsize=(9.9,12));\n",
    "\n",
    "#############\n",
    "# Loss plot #\n",
    "#############\n",
    "ax1 = plt.subplot(5,1,1);\n",
    "\n",
    "# Add grid to axes\n",
    "plt.grid(color='k',alpha=0.25);\n",
    "\n",
    "# Linear grid of training epochs\n",
    "epochs = arange(0,N_epoch);\n",
    "\n",
    "# Cross-entropy error (dB) - training set\n",
    "plt.plot(epochs,10 * log10(\n",
    "    model.history.history['loss']),\n",
    "    '.-',c='g',alpha=0.5,\n",
    "    label=train_set_lbl);\n",
    "\n",
    "# Cross-entropy error (dB) - validation set\n",
    "plt.plot(epochs,10 * log10(\n",
    "    model.history.history['val_loss']),\n",
    "    '.-',c='k',alpha=0.5,\n",
    "    label=val_set_lbl);\n",
    "\n",
    "# Set x-axis limits\n",
    "plt.xlim([epochs[0],epochs[-1]]);\n",
    "\n",
    "# Title\n",
    "plt.title(r'Cross-Entropy Error vs. Training Epoch $\\varepsilon$',\n",
    "          fontsize=16,weight='bold');\n",
    "\n",
    "# x-axis label\n",
    "plt.xlabel(r'Epoch $\\varepsilon$',fontsize=14);\n",
    "\n",
    "# y-axis label\n",
    "plt.ylabel(r'Error${}_{\\varepsilon}$ (dB)',fontsize=14);\n",
    "\n",
    "# Legend\n",
    "plt.legend();\n",
    "\n",
    "#################\n",
    "# Accuracy plot #\n",
    "#################\n",
    "plt.subplot(5,1,2,sharex=ax1);\n",
    "\n",
    "# Add grid to axes\n",
    "plt.grid(color='k',alpha=0.25);\n",
    "\n",
    "# Cross-entropy error (dB) - training set\n",
    "plt.plot(epochs,model.history.history['categorical_accuracy'],\n",
    "    '.-',c='g',alpha=0.5,label=train_set_lbl);\n",
    "\n",
    "# Cross-entropy error (dB) - validation set\n",
    "plt.plot(epochs,model.history.history['val_categorical_accuracy'],\n",
    "    '.-',c='k',alpha=0.5,label=val_set_lbl);\n",
    "\n",
    "# Set x-axis limits\n",
    "plt.xlim([epochs[0],epochs[-1]]);\n",
    "\n",
    "# Title\n",
    "plt.title(r'Categorical Accuracy vs. Training Epoch $\\varepsilon$',\n",
    "          fontsize=16,weight='bold');\n",
    "\n",
    "# x-axis label\n",
    "plt.xlabel(r'Epoch $\\varepsilon$',fontsize=14);\n",
    "\n",
    "# y-axis label\n",
    "plt.ylabel(r'Accuracy${}_{\\varepsilon}$ ($\\times100\\%$)',fontsize=14);\n",
    "\n",
    "# Legend\n",
    "plt.legend();\n",
    "\n",
    "##################\n",
    "# Precision plot #\n",
    "##################\n",
    "plt.subplot(5,1,3,sharex=ax1);\n",
    "\n",
    "# Add grid to axes\n",
    "plt.grid(color='k',alpha=0.25);\n",
    "\n",
    "# Cross-entropy error (dB) - training set\n",
    "plt.plot(epochs,model.history.history['precision'],\n",
    "    '.-',c='g',alpha=0.5,label=train_set_lbl);\n",
    "\n",
    "# Cross-entropy error (dB) - validation set\n",
    "plt.plot(epochs,model.history.history['val_precision'],\n",
    "    '.-',c='k',alpha=0.5,label=val_set_lbl);\n",
    "\n",
    "# Set x-axis limits\n",
    "plt.xlim([epochs[0],epochs[-1]]); \n",
    "\n",
    "# x-axis label\n",
    "plt.xlabel(r'Epoch $\\varepsilon$',fontsize=14);\n",
    "\n",
    "# y-axis label\n",
    "plt.ylabel(r'Precision${}_{\\varepsilon}$',fontsize=14);\n",
    "\n",
    "# Legend\n",
    "plt.legend();\n",
    "\n",
    "###############\n",
    "# Recall plot #\n",
    "###############\n",
    "plt.subplot(5,1,4,sharex=ax1);\n",
    "\n",
    "# Add grid to axes\n",
    "plt.grid(color='k',alpha=0.25);\n",
    "\n",
    "# Cross-entropy error (dB) - training set\n",
    "plt.plot(epochs,model.history.history['recall'],\n",
    "    '.-',c='g',alpha=0.5,label=train_set_lbl);\n",
    "\n",
    "# Cross-entropy error (dB) - validation set\n",
    "plt.plot(epochs,model.history.history['val_recall'],\n",
    "    '.-',c='k',alpha=0.5,label=val_set_lbl);\n",
    "\n",
    "# Set x-axis limits\n",
    "plt.xlim([epochs[0],epochs[-1]]);\n",
    "\n",
    "# Title\n",
    "plt.title(r'Recall vs. Training Epoch $\\varepsilon$',\n",
    "          fontsize=16,weight='bold');\n",
    "\n",
    "# x-axis label\n",
    "plt.xlabel(r'Epoch $\\varepsilon$',fontsize=14);\n",
    "\n",
    "# y-axis label\n",
    "plt.ylabel(r'Recall${}_{\\varepsilon}$',fontsize=14);\n",
    "\n",
    "# Legend\n",
    "plt.legend();\n",
    "\n",
    "############\n",
    "# AUC plot #\n",
    "############\n",
    "plt.subplot(5,1,5,sharex=ax1);\n",
    "\n",
    "# Add grid to axes\n",
    "plt.grid(color='k',alpha=0.25);\n",
    "\n",
    "# Cross-entropy error (dB) - training set\n",
    "plt.plot(epochs,model.history.history['auc'],\n",
    "    '.-',c='g',alpha=0.5,label=train_set_lbl);\n",
    "\n",
    "# Cross-entropy error (dB) - validation set\n",
    "plt.plot(epochs,model.history.history['val_auc'],\n",
    "    '.-',c='k',alpha=0.5,label=val_set_lbl);\n",
    "\n",
    "# Set x-axis limits\n",
    "plt.xlim([epochs[0],epochs[-1]]);\n",
    "\n",
    "# Title\n",
    "plt.title(r'Area Under ROC Curve vs. Training Epoch $\\varepsilon$',\n",
    "          fontsize=16,weight='bold');\n",
    "\n",
    "# x-axis label\n",
    "plt.xlabel(r'Epoch $\\varepsilon$',fontsize=14);\n",
    "\n",
    "# y-axis label\n",
    "plt.ylabel(r'AUC${}_{\\varepsilon}$',fontsize=14);\n",
    "\n",
    "# Legend\n",
    "plt.legend();\n",
    "\n",
    "# Optimize layout\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\textbf{Pass Entire Dataset (i.e., Train }\\cup\\textbf{ Validation) to Model}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C x 1 class prediction for entire dataset\n",
    "Y_hat = model.predict(\n",
    "    X,                        # Input data\n",
    "    batch_size=N_batch,       # Batch size\n",
    ");\n",
    "\n",
    "# Cast 1-hot class labels as ordinal labels\n",
    "y_hat = argmax(Y_hat,axis=1); # Predictions\n",
    "y_true = argmax(Y,axis=1);    # Ground truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\textbf{Confusion Matrix Using Predictions Output Above}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "#    Compute Matrix:    #\n",
    "#########################\n",
    "\n",
    "# Use the sklearn confusion matrix function\n",
    "confusion_mat = confusion_matrix(y_true,y_hat,\n",
    "    labels=[c for c in range(C)],sample_weight=None);\n",
    "\n",
    "#########################\n",
    "#   Confusion Plotter:  # - adapated from online example\n",
    "#########################\n",
    "\n",
    "def plot_confusion_matrix(C,classes,normalize=False,\n",
    "            title='Confusion matrix',cmap=plt.cm.Greens):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Let epsilon > 0 be small...\n",
    "    epsilon = 1e-7;\n",
    "    \n",
    "    # Normalization of confusion matrix C\n",
    "    if normalize:\n",
    "        C = C.astype('float') / (epsilon + C.sum(axis=1)[:, newaxis]);\n",
    "\n",
    "    # Print the matrix C\n",
    "    print(C);\n",
    "    \n",
    "    # Image representation\n",
    "    ax = plt.gca();   # <-- grab current axes\n",
    "    C = flipud(C);    # <-- flip horizontally for visualization\n",
    "    im = ax.imshow(C,cmap=cmap);\n",
    "    \n",
    "    # Colorbar\n",
    "    colorbar(im);\n",
    "    \n",
    "    # Title\n",
    "    plt.title(title,fontsize=20,weight=\"bold\");\n",
    "    \n",
    "    # Tick labels\n",
    "    tick_marks = arange(len(classes));\n",
    "    plt.xticks(tick_marks, classes, rotation=45,fontweight=\"bold\");\n",
    "    \n",
    "    # Overwrite default y-axis limits\n",
    "    plt.ylim([-0.5,len(classes)-0.5]);\n",
    "\n",
    "    # Text labels in tiles (i.e., elements)\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = C.max() / 2.\n",
    "    for i, j in iter_prod(range(C.shape[0]), range(C.shape[1])):\n",
    "        plt.text(j, i, format(C[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",weight=\"bold\",\n",
    "                 color=\"white\" if C[i, j] > thresh else \"black\")\n",
    "\n",
    "    # x-axis labels\n",
    "    plt.ylabel('True label',fontsize=16,weight=\"bold\");\n",
    "    \n",
    "    # y-axis labels\n",
    "    plt.xlabel('Predicted label',fontsize=16,weight=\"bold\");\n",
    "    \n",
    "    # Set axis layout\n",
    "    plt.tight_layout();\n",
    "    \n",
    "#########################\n",
    "#    Scale Colorbar:    # - found this online\n",
    "#########################\n",
    "\n",
    "def colorbar(mappable):\n",
    "    last_axes = plt.gca()\n",
    "    ax = mappable.axes\n",
    "    fig = ax.figure\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    cbar = fig.colorbar(mappable, cax=cax)\n",
    "    plt.sca(last_axes)\n",
    "    return cbar\n",
    "\n",
    "\n",
    "#########################\n",
    "#    Visualization:     #\n",
    "#########################\n",
    "\n",
    "conf_fig = plt.figure(figsize=(9.9,9.9));\n",
    "plot_confusion_matrix(\n",
    "    confusion_mat, \n",
    "    classes=[clss for clss in class_table],\n",
    "    normalize=True,\n",
    "    title='Confusion Matrix',\n",
    "    cmap=plt.cm.Greens);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
